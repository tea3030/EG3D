{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tea3030/EG3D/blob/main/%5B4%EA%B8%B0%5D_%5B%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A5%BC_%EC%9C%84%ED%95%9C_%ED%94%84%EB%A1%AC%ED%94%84%ED%8A%B8_%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%5D_Week2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://drive.google.com/uc?id=1P3EeqqSoOkb9M628bgHWaLHIDT7RNri2\" width=\"800\"></center>\n"
      ],
      "metadata": {
        "id": "oDUy9d29m5lw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'><b>[ Warning ]</b></font> **ë¬´ë‹¨ ë„ìš©, ë³µì œ ë° ë¬´ë‹¨ ë°°í¬ ê¸ˆì§€ ì•ˆë‚´**\n",
        "\n",
        "```\n",
        "ğŸš¨\n",
        "ì €ì‘ê¶Œë²•ì— ë”°ë¼ ê°•ì˜ì— ì‚¬ìš©í•œ ëª¨ë“  ì €ì‘ë¬¼(ì½”ë“œ, í”„ë¡¬í”„íŠ¸, PDF, ì‹¤ìŠµìë£Œ)ë¥¼ ë¶ˆë²• ë³µì œí•˜ê±°ë‚˜ ì™¸ë¶€ì— ë¬´ë‹¨ ìœ ì¶œí•˜ëŠ” ê²½ìš° ë²•ì  ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "```"
      ],
      "metadata": {
        "id": "rK5zrbLWum9y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQIfsHYFSLAL"
      },
      "source": [
        "# Prompt Engineering ì‹¤ìŠµ ì‹œì‘\n",
        "\n",
        "> Prompt Engineeringì˜ ì‹¤ìŠµì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì´ë²ˆ Colabì—ì„œëŠ” Prompt Engineering ê°•ì˜ë¥¼ ìˆ˜ê°•í•˜ì‹œë©´ì„œ ë°°ìš´ ë‹¤ì–‘í•œ ì§€ì‹ë“¤ì„ ì‹¤ìŠµì„ í†µí•´ì„œ í™œìš©í•´ ë³¼ ì‹œê°„ì„ ê°€ì§ˆê²ë‹ˆë‹¤!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WCH74DnO6iT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thLAzl8dhetp"
      },
      "source": [
        "## 0ï¸âƒ£ ì‹¤ìŠµ ì „ í”„ë¡œì íŠ¸ ì…‹ì—…\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCGaBi7RQ9Mz"
      },
      "source": [
        "```\n",
        "ğŸ’¡\n",
        "colab ê°™ì€ ê²½ìš°, sessionìœ¼ë¡œ ê´€ë¦¬ê°€ ë©ë‹ˆë‹¤.\n",
        "ì¼ì • ì‹œê°„ì´ ì§€ë‚  ë™ì•ˆ ì•„ë¬´ëŸ° ë™ì‘ì„ í•˜ì§€ ì•Šê±°ë‚˜,\n",
        "ìƒˆë¡œìš´ ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†í•œ ê²½ìš° ì•„ë˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ë‹¤ì‹œ ì„¤ì¹˜í•´ì•¼í•©ë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âš™ï¸ <font color='Darkorange'><b>[ ì„¤ì • ]</b></font> ì‹¤ìŠµ ì§„í–‰ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‹¤ìš´ë¡œë“œ"
      ],
      "metadata": {
        "id": "vV78JhlGulSv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì‹¤ìŠµì„ ì§„í–‰í•˜ê¸° ìœ„í•´ì„œëŠ” ê° AIì„œë¹„ìŠ¤ë“¤ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„¤ì¹˜í•´ì•¼í•©ë‹ˆë‹¤. ì•„ë˜ ì½”ë“œ ë¸”ëŸ­ì„ ì‹¤í–‰í•´ì„œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ë´…ì‹œë‹¤!\n",
        "\n",
        "```\n",
        "ğŸ’¡\n",
        "ì•ìœ¼ë¡œ ì•„ë˜ ë¸”ëŸ­ê³¼ ê°™ì€ ì½”ë“œ ë¸”ëŸ­ì€\n",
        "í•´ë‹¹ ë¸”ëŸ­ì„ í´ë¦­í•˜ì‹  ë‹¤ìŒ ì™¼ìª½ì˜ ì‹¤í–‰ë²„íŠ¼(â–¶ï¸)ì„ í´ë¦­í•˜ê±°ë‚˜, `shift + Enter` ë‹¨ì¶•í‚¤ë¥¼ í†µí•´ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
        "```"
      ],
      "metadata": {
        "id": "JZUGiU5duuuA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uez8c3NIrQQT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "collapsed": true,
        "outputId": "e097e16a-64b9-4cd4-a241-e080d5daa8f1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.6)\n",
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.11/dist-packages (0.45.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKk1S6pcQ9Mz"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ğŸ’ <font color='Aqua'><b>[ ì •ë³´ ]</b></font>  colabì—ì„œ secret keyë¡œ ë“±ë¡í•˜ëŠ” ë°©ë²•"
      ],
      "metadata": {
        "id": "ZoQ2eqG0TKhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ê° ì‹¤ìŠµì„ ì§„í–‰í•˜ê¸° ìœ„í•´ì„œ OpenAI, Claudeì™€ ê°™ì€ ì„œë¹„ìŠ¤ë“¤ì˜ API KEY ë“±ë¡ì´ í•„ìš”í•©ë‹ˆë‹¤.  \n",
        "ê³µìœ ë“œë¦° [ë…¸ì…˜ ë§í¬](https://www.notion.so/Fast-Campus-a75a0653415f4071adfa68dd793182f4?pvs=4#24a0f6693d714a37a68918750c4a85f2)ë¥¼ ì°¸ê³ í•´ì„œ ê° ì„œë¹„ìŠ¤ë“¤ì˜ API KEYë¥¼ ë°œê¸‰ ë°›ì•„ì£¼ì„¸ìš”.\n",
        "\n",
        "ê° API KEYë“¤ì„ ëª¨ë‘ ë°œê¸‰ ë°›ìœ¼ì…¨ë‹¤ë©´, ì´ì œ ê° API KEYë¥¼ ë³€ìˆ˜ë¡œ ë“±ë¡í•´ë´…ì‹œë‹¤!"
      ],
      "metadata": {
        "id": "Q_ZsjOwNu21C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. ì™¼ìª½ ë°”ì—ì„œ í‚¤(ğŸ”‘) ë²„íŠ¼ì„ í´ë¦­í•´ì„œ `+ìƒˆ ë³´ì•ˆ ë¹„ë°€ ì¶”ê°€`ë¥¼ í†µí•´ ì‹œí¬ë¦¿ í‚¤ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
        "<img src=\"https://drive.google.com/uc?id=1tW_cFroWbk9cXA_N9Av8llFdQqhDA4p7\" alt=\"colabì—ì„œ secret key ë“±ë¡\" width=\"800\"/>\n",
        " <br/>\n",
        " <br/>\n",
        " <br/>\n",
        "\n",
        "2. ì´ë¦„, ê°’ì„ ì…ë ¥í•˜ê³  ë…¸íŠ¸ë¶ ì—‘ì„¸ìŠ¤ë¥¼ í—ˆìš©í•©ë‹ˆë‹¤.  \n",
        "<img src=\"https://drive.google.com/uc?id=1nBL6qRmxPksAq7NbE2xSagVjAtToaJ1F\" alt=\"colabì—ì„œ secret key ë“±ë¡2\" width=\"600\"/>\n",
        "<br/>\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "\n",
        "\n",
        "3. ê° API Keyë“¤ì„ `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`, `GOOGLE_API_KEY` ë¡œ ë“±ë¡í•´ì£¼ì„¸ìš”.\n",
        "<img src=\"https://drive.google.com/uc?id=1zqeJ5DF0QvMROWUnLKV1HiOJRd7ZYvsV\" alt=\"colabì—ì„œ secret key ë“±ë¡3\" width=\"600\"/>"
      ],
      "metadata": {
        "id": "NX1-Ge7vTedV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âš™ï¸ <font color='Darkorange'><b>[ ì„¤ì • ]</b></font> ê¸°íƒ€ colab ì„¤ì •"
      ],
      "metadata": {
        "id": "ESqM4BtA0-5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì•„ë˜ ì½”ë“œëŠ” ì¶œë ¥ ê²°ê³¼ë¥¼ wrapping í•©ë‹ˆë‹¤. ì¤„ì´ ë„ˆë¬´ ê¸¸ì–´ì§€ë©´ ìë™ìœ¼ë¡œ ì¤„ë°”ê¿ˆì„ í•˜ë„ë¡ í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤!"
      ],
      "metadata": {
        "id": "pvHuUACR1E_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "8PLZi-oA0-Ct",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "66a8a76e-57c9-4b1d-ff3a-82d76fcfeff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âš™ï¸ <font color='Darkorange'><b>[ ì„¤ì • ]</b></font> colabì—ì„œ secret keyë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜ ì‹¤í–‰í•˜ê¸°"
      ],
      "metadata": {
        "id": "NFE3u9dFV8VW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9PswB5prJJ9"
      },
      "source": [
        "ì´ì œ ë“±ë¡í•œ API KEYë¥¼ ì‹¤ì œë¡œ ìš”ì²­í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” í•¨ìˆ˜ë„ ì‘ì„± í›„ ì‹¤í–‰í•´ë´…ì‹œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = (userdata.get('OPENAI_API_KEY')).strip()\n",
        "ANTHROPIC_API_KEY = (userdata.get('ANTHROPIC_API_KEY')).strip()\n",
        "GOOGLE_API_KEY = (userdata.get('GOOGLE_API_KEY')).strip()"
      ],
      "metadata": {
        "id": "xXmB4D-qlWlz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "baddd0e6-932c-4083-bc98-8111a0dfd5c6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì´ì œ keyë¥¼ ì¶œë ¥í•´ì„œ colabì— ë“±ë¡í•œ api keyë¥¼ ì˜ ê°€ì ¸ì™”ëŠ”ì§€ í™•ì¸í•´ë´…ì‹œë‹¤."
      ],
      "metadata": {
        "id": "S3IhRHTZrTWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "JqWpIz1orJh-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "47ebce01-f071-42ba-b430-51529bc7dbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sk-7jikUpKzTA5A93hjNyrqMF3v7hj5SrJvEMJDJ0H2tiT3BlbkFJvlwQ0ML8th-QBHzT6rLujc9zQByyGVx3W6YOPdov8A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzIYxw2lkQiX"
      },
      "source": [
        "ìœ„ ì½”ë“œ ë¸”ëŸ­ì˜ ì‹¤í–‰ê²°ê³¼ë¡œ OPENAIì˜ API KEYë¡œ ë“±ë¡í•œ ê°’ì´ ë™ì¼í•˜ê²Œ ì¶œë ¥ë˜ì—ˆë‚˜ìš”? ê·¸ëŸ¼ ì´ì œ ì‹¤ìŠµì„ ìœ„í•œ ëª¨ë“  ì¤€ë¹„ê°€ ëì´ ë‚¬ìŠµë‹ˆë‹¤! ğŸ‘ğŸ‘ğŸ‘\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "```\n",
        "ğŸ’¡\n",
        "ë¸Œë¼ìš°ì €ë¥¼ ìƒˆë¡œ ì‹œì‘í•˜ê±°ë‚˜ ì„¸ì…˜ì´ ë§Œë£Œëœ ë’¤ ë‹¤ì‹œ ì‹œì‘í•  ë•ŒëŠ”\n",
        "[ ì„¤ì • ] ì„¹ì…˜ì„ ëª¨ë‘ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì…”ì•¼ í•©ë‹ˆë‹¤.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### âš™ï¸ <font color='Darkorange'><b>[ ì„¤ì • ]</b></font> OpenAI ëª¨ë¸ í˜¸ì¶œ í•¨ìˆ˜ ì •ì˜\n",
        "\n",
        "\n",
        "API ì‚¬ìš© ë°©ë²•ì„ ë” ìì„¸íˆ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´,  \n",
        "[OpenAI Docs Link](https://platform.openai.com/docs/guides/text-generation)\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "<ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡>\n",
        "* gpt-4o\n",
        "* gpt-4o-mini\n",
        "* gpt-4-turbo"
      ],
      "metadata": {
        "id": "uGVGdFq-SrkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from enum import Enum\n",
        "\n",
        "openai_client = OpenAI(\n",
        "    api_key=OPENAI_API_KEY\n",
        ")\n",
        "\n",
        "class OpenAIModel(Enum):\n",
        "    GPT_4O = \"chatgpt-4o-latest\"\n",
        "    GPT_4O_MINI = \"gpt-4o-mini\"\n",
        "    GPT_4_TURBO = \"gpt-4-turbo\"\n",
        "\n",
        "\n",
        "def openai_request(user_input: str,\n",
        "                   system_prompt: str | None = None,\n",
        "                   model: str = OpenAIModel.GPT_4O_MINI,\n",
        "                   temperature: float = 0.5,\n",
        "                   max_tokens: int = 1000):\n",
        "\n",
        "    # -- set messages\n",
        "    messages = []\n",
        "\n",
        "    if system_prompt:\n",
        "        messages.append(\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_prompt\n",
        "            }\n",
        "        )\n",
        "\n",
        "    if user_input:\n",
        "        messages.append(\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": user_input\n",
        "            }\n",
        "        )\n",
        "\n",
        "    completion = openai_client.chat.completions.create(\n",
        "        model=model.value,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "\n",
        "    # print(completion.choices[0].message)\n",
        "    return completion.choices[0].message"
      ],
      "metadata": {
        "id": "JKxVDYf02KSj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7bb787c1-9bc6-46f7-a571-ba6a7eaad734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='yellow'><b>[ ì˜µì…˜ ]</b></font>  \n",
        "í•¨ìˆ˜ê°€ ì˜ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì½”ë“œ ë¸”ëŸ­ì˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ì‹¤í–‰í•´ë´…ì‹œë‹¤!  \n",
        "ì£¼ì„ì„ í•´ì œí•˜ê¸° ìœ„í•´, ì½”ë“œ ë¸”ëŸ­ì„ ì „ì²´ ì„ íƒí•˜ê³  `ctrl(cmd)` + `/` ì„ í†µí•´ ì£¼ì„ì„ í•´ì œí•©ë‹ˆë‹¤.  \n",
        "(apië¡œ ìš”ì²­ì„ í•  ë•Œë§ˆë‹¤ ë¹„ìš©ì´ ë°œìƒí•˜ê¸° ë•Œë¬¸ì— ì£¼ì„*ì²˜ë¦¬ë¥¼ í•´ë‘ì—ˆìŠµë‹ˆë‹¤.)\n",
        "\n",
        "```\n",
        "ğŸ’¡\n",
        "`ì£¼ì„`ì€ ì½”ë“œ ì†ì˜ ë©”ëª¨ë¼ê³  ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•  ë•Œ ë¬´ì‹œë˜ë©°,\n",
        "ì½”ë“œë¥¼ ì–´ë–¤ ì—­í• ì„ í•˜ëŠ” ì§€ ì„¤ëª…í•´ ì‰½ê²Œ ì´í•´í•˜ê±°ë‚˜,\n",
        "ê¸°ì–µí•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ì„¤ëª…ì…ë‹ˆë‹¤.\n",
        "```\n"
      ],
      "metadata": {
        "id": "R2Xi9-URg5Hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # # -- Test\n",
        "\n",
        "# result = openai_request(\n",
        "#     system_prompt=\"You're kind ai assistant. Answer in natural korean language.\",\n",
        "#     user_input=\"ì•ˆë…•\",\n",
        "#     model=OpenAIModel.GPT_4O_MINI\n",
        "# )\n",
        "\n",
        "# print(result)"
      ],
      "metadata": {
        "id": "5Kwcx0FHfTFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### âš™ï¸ <font color='Darkorange'><b>[ ì„¤ì • ]</b></font> Anthropic ëª¨ë¸ í˜¸ì¶œ í•¨ìˆ˜ ì •ì˜\n",
        "\n",
        "API ì‚¬ìš© ë°©ë²•ì„ ë” ìì„¸íˆ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´,  \n",
        "[Anthropic Docs Link](https://docs.anthropic.com/en/api/messages)\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "**ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ [[link]](https://docs.anthropic.com/en/docs/about-claude/models)>**  \n",
        "* claude 3.5 sonnet\n",
        "* claude 3 opus\n",
        "* claude 3 sonnet\n",
        "* claude 3 haiku\n",
        "<br/>\n",
        "<br/>"
      ],
      "metadata": {
        "id": "TCY0cy0GTBaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ëª¨ë¸ë³„ ë¹„ìš© ë° ì„±ëŠ¥**>  \n",
        "<img src=\"https://mintlify.s3-us-west-1.amazonaws.com/anthropic/images/3-5-sonnet-curve.png\" width=300/>"
      ],
      "metadata": {
        "id": "HcCNYtn9nBe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import anthropic\n",
        "from enum import Enum\n",
        "\n",
        "\n",
        "anthropic_client = anthropic.Anthropic(\n",
        "    api_key=ANTHROPIC_API_KEY\n",
        ")\n",
        "\n",
        "class ClaudeModel(Enum):\n",
        "    CLAUDE_35_SONNET = \"claude-3-5-sonnet-20240620\"\n",
        "    CLAUDE_3_OPUS = \"claude-3-opus-20240229\"\n",
        "    CLAUDE_3_SONNET = \"claude-3-sonnet-20240229\"\n",
        "    CLAUDE_3_HAIKU = \"claude-3-haiku-20240307\"\n",
        "\n",
        "def anthropic_request(user_input: str,\n",
        "                   system_prompt: str | None = None,\n",
        "                   model: str = ClaudeModel.CLAUDE_3_HAIKU,\n",
        "                   temperature: float = 0.5,\n",
        "                   max_tokens: int = 1000):\n",
        "\n",
        "    if system_prompt:\n",
        "        completion = anthropic_client.messages.create(\n",
        "            model=model.value,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            system=system_prompt,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": user_input}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        completion = anthropic_client.messages.create(\n",
        "            model=model.value,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": user_input}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    # print(completion)\n",
        "    return completion.content"
      ],
      "metadata": {
        "id": "GG-dTCDdjK7O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c3fd4550-e893-4a78-94e0-8861b10c1248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='yellow'><b>[ ì˜µì…˜ ]</b></font>  \n",
        "í•¨ìˆ˜ê°€ ì˜ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì½”ë“œ ë¸”ëŸ­ì˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ì‹¤í–‰í•´ë´…ì‹œë‹¤!  \n",
        "ì£¼ì„ì„ í•´ì œí•˜ê¸° ìœ„í•´, ì½”ë“œ ë¸”ëŸ­ì„ ì „ì²´ ì„ íƒí•˜ê³  `ctrl(cmd)` + `/` ì„ í†µí•´ ì£¼ì„ì„ í•´ì œí•©ë‹ˆë‹¤.  \n",
        "(apië¡œ ìš”ì²­ì„ í•  ë•Œë§ˆë‹¤ ë¹„ìš©ì´ ë°œìƒí•˜ê¸° ë•Œë¬¸ì— ì£¼ì„ì²˜ë¦¬ë¥¼ í•´ë‘ì—ˆìŠµë‹ˆë‹¤.)"
      ],
      "metadata": {
        "id": "8ROxHYfkmuI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # -- Test\n",
        "\n",
        "result = anthropic_request(\n",
        "    system_prompt=\"You are kind ai assistant. You always answer in natural korean.\",\n",
        "    user_input=\"Hi\"\n",
        ")\n",
        "\n",
        "# print(result)"
      ],
      "metadata": {
        "id": "LcZfurMimknH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8a54b9ce-dd90-4f8f-a4be-1ce846cbbeeb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### âš™ï¸ <font color='Darkorange'><b>[ ì„¤ì • ]</b></font> Gemini ëª¨ë¸ í˜¸ì¶œ í•¨ìˆ˜ ì •ì˜\n",
        "\n",
        "API ì‚¬ìš© ë°©ë²•ì„ ë” ìì„¸íˆ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´,  \n",
        "[Gemini Docs Link](https://ai.google.dev/gemini-api/docs/text-generation?lang=python)\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "**ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ [[link]](https://docs.anthropic.com/en/docs/about-claude/models)>**  \n",
        "* gemini-1.5-flash\n",
        "<br/>\n",
        "<br/>"
      ],
      "metadata": {
        "id": "n8isqbiRm3jO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from enum import Enum\n",
        "\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "class GoogleModel(Enum):\n",
        "    GEMINI_15_FLASH = \"gemini-1.5-flash\"\n",
        "\n",
        "def gemini_prompt_generator(system_prompt: str,\n",
        "                            user_input: str):\n",
        "    return \"\\n\".join([system_prompt, user_input])\n",
        "\n",
        "\n",
        "def gemini_request(user_input: str,\n",
        "                   model: str = GoogleModel.GEMINI_15_FLASH,\n",
        "                   temperature: float = 0.7,\n",
        "                   max_tokens: int = 150):\n",
        "\n",
        "    model = genai.GenerativeModel(model.value)\n",
        "    response = model.generate_content(\n",
        "        user_input,\n",
        "        generation_config={\n",
        "            'max_output_tokens': max_tokens,\n",
        "            'temperature': temperature\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # print(response)\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "c4ieU3nboz-g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5f57e5af-b522-495b-bcec-f6d424a9dd32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='yellow'><b>[ ì˜µì…˜ ]</b></font>  \n",
        "í•¨ìˆ˜ê°€ ì˜ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì½”ë“œ ë¸”ëŸ­ì˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ì‹¤í–‰í•´ë´…ì‹œë‹¤!  \n",
        "ì£¼ì„ì„ í•´ì œí•˜ê¸° ìœ„í•´, ì½”ë“œ ë¸”ëŸ­ì„ ì „ì²´ ì„ íƒí•˜ê³  `ctrl(cmd)` + `/` ì„ í†µí•´ ì£¼ì„ì„ í•´ì œí•©ë‹ˆë‹¤.  \n",
        "(apië¡œ ìš”ì²­ì„ í•  ë•Œë§ˆë‹¤ ë¹„ìš©ì´ ë°œìƒí•˜ê¸° ë•Œë¬¸ì— ì£¼ì„ì²˜ë¦¬ë¥¼ í•´ë‘ì—ˆìŠµë‹ˆë‹¤.)"
      ],
      "metadata": {
        "id": "6uImKvuNtzOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # -- Test\n",
        "\n",
        "result = gemini_request(user_input = \"hi\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "U1kmLMO1th6J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d80deaf8-0a22-4ee1-d4ae-4bd61198dab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi there! How can I help you today?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### âš™ï¸ <font color='Darkorange'><b>[ ì„¤ì • ]</b></font> DeepSeek ëª¨ë¸ í˜¸ì¶œ í•¨ìˆ˜ ì •ì˜\n",
        "\n",
        "API ì‚¬ìš© ë°©ë²•ì„ ë” ìì„¸íˆ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´,  \n",
        "[DeepSeek API Docs Link](https://api-docs.deepseek.com/)\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "**ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ [[link]](https://api-docs.deepseek.com/quick_start/pricing)>**  \n",
        "* deepseek-chat\n",
        "<br/>\n",
        "<br/>"
      ],
      "metadata": {
        "id": "THuYhjtgX9WF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Please install OpenAI SDK first: `pip3 install openai`\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=\"\", base_url=\"https://api.deepseek.com\")\n",
        "\n",
        "def deepseek_request(system_prompt: str, user_input: str):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"deepseek-chat\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_input},\n",
        "        ],\n",
        "        stream=False\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "LOWQETOia6ap",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "dfe7e654-6e38-4958-a216-c76edee92499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='yellow'><b>[ ì˜µì…˜ ]</b></font>  \n",
        "í•¨ìˆ˜ê°€ ì˜ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì½”ë“œ ë¸”ëŸ­ì˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ì‹¤í–‰í•´ë´…ì‹œë‹¤!  \n",
        "ì£¼ì„ì„ í•´ì œí•˜ê¸° ìœ„í•´, ì½”ë“œ ë¸”ëŸ­ì„ ì „ì²´ ì„ íƒí•˜ê³  `ctrl(cmd)` + `/` ì„ í†µí•´ ì£¼ì„ì„ í•´ì œí•©ë‹ˆë‹¤.  \n",
        "(apië¡œ ìš”ì²­ì„ í•  ë•Œë§ˆë‹¤ ë¹„ìš©ì´ ë°œìƒí•˜ê¸° ë•Œë¬¸ì— ì£¼ì„ì²˜ë¦¬ë¥¼ í•´ë‘ì—ˆìŠµë‹ˆë‹¤.)"
      ],
      "metadata": {
        "id": "2HLSZ75fcOrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # í…ŒìŠ¤íŠ¸ ì…ë ¥\n",
        "    system_prompt = \"You are a helpful assistant. Answer in natural Korean.\"\n",
        "    result = deepseek_request(system_prompt=system_prompt, user_input=\"hi\")\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "J5yRJSDCcOX3",
        "outputId": "5c0c2377-f644-473a-e863-c43a9b13b864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "APIConnectionError",
          "evalue": "Connection error.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLocalProtocolError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 ) as trace:\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"send_request_body\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_send_request_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLocalProtocolError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLocalProtocolError\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             event = h11.Request(\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_exceptions.py\u001b[0m in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_exc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mto_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mraise\u001b[0m  \u001b[0;31m# pragma: nocover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLocalProtocolError\u001b[0m: Illegal header value b'Bearer '",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mLocalProtocolError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m             response = self._client.send(\n\u001b[0m\u001b[1;32m    997\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mmapped_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLocalProtocolError\u001b[0m: Illegal header value b'Bearer '",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-769749e2ea7d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# í…ŒìŠ¤íŠ¸ ì…ë ¥\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msystem_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"You are a helpful assistant. Answer in natural Korean.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepseek_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msystem_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msystem_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-bcceb38592ea>\u001b[0m in \u001b[0;36mdeepseek_request\u001b[0;34m(system_prompt, user_input)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdeepseek_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msystem_prompt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"deepseek-chat\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    857\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    858\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    860\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         )\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    961\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1021\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1021\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Raising connection error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAPIConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         log.debug(\n",
            "\u001b[0;31mAPIConnectionError\u001b[0m: Connection error."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ğŸ’ <font color='Aqua'><b>[ ì •ë³´ ]</b></font> ê° API Request í•¨ìˆ˜ í˜¸ì¶œ ë°©ë²•"
      ],
      "metadata": {
        "id": "tY73jAvE4qFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì•„ë˜ ì½”ë“œëŠ” ìœ„ì—ì„œ ì •ì˜í•œ ëª¨ë¸ í˜¸ì¶œ í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•˜ëŠ” ì˜ˆì‹œë“¤ì…ë‹ˆë‹¤. ì•ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ì‹¤ìŠµì—ì„œëŠ” ì•„ë˜ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì…”ì•¼ í•©ë‹ˆë‹¤. ê° í•¨ìˆ˜ë“¤ì— ëŒ€í•´ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤!\n",
        "\n",
        "* `openai_request`ì™€ `anthropic_request` í•¨ìˆ˜ë“¤ì€ `system_prompt`ì™€ `user_input` íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì‹¤ìŠµì—ì„œ system promptì™€ user_input ì´ êµ¬ë¶„ë˜ì–´ ìˆë‹¤ë©´ ì•„ë˜ì™€ ê°™ì´ ì‚¬ìš©í•´ì£¼ì„¸ìš”."
      ],
      "metadata": {
        "id": "YaGNzSWeJT6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You're kind ai assistant. Answer in natural korean language.\"\n",
        "user_input = \"Hi!\"\n",
        "\n",
        "# # # -- OpenAI Request\n",
        "# # openai_result = openai_request(system_prompt=system_prompt,\n",
        "# #                         user_input=user_input)\n",
        "# # print(f\"# OpenAI Result: {openai_result.content}\")\n",
        "# # print(\"-\"*20)\n",
        "\n",
        "# # -- Anthropic Request\n",
        "# anthropic_result = anthropic_request(system_prompt=system_prompt,\n",
        "#                            user_input=user_input)\n",
        "# print(f\"# Anthropic Result: {anthropic_result[0].text}\")\n",
        "\n",
        "# -- DeepSeek Request\n",
        "# deepseek_result = deepseek_request(system_prompt=system_prompt,\n",
        "#                                    user_input=user_input)\n",
        "# print(f\"# DeepSeek Result: {deepseek_result}\")\n",
        "# print(\"-\" * 20)"
      ],
      "metadata": {
        "id": "HwTTFg9X4ra5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb603dc-2141-473a-e9e9-e05503882046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# DeepSeek Result: Hello! How can I assist you today? ğŸ˜Š\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ë§Œì•½ ì‹¤ìŠµì—ì„œ system promptì™€ user inputì´ êµ¬ë¶„ë˜ì–´ ìˆì§€ ì•Šë‹¤ë©´, `openai_request`ì™€ `anthropic_request`ì™€ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•  ë•Œ `user_input`ì—ë§Œ ê°’ì„ ë„£ì–´ì£¼ì„¸ìš”.  \n",
        "(apiì— ìš”ì²­ì„ ë³´ë‚¼ ë•Œ system promptëŠ” ì„ íƒì (optional)ì´ì§€ë§Œ, user inputê°’ì€ í•„ìˆ˜(required)ë¡œ í¬í•¨í•´ì„œ ìš”ì²­ì„ í•´ì•¼í•´ìš”.)"
      ],
      "metadata": {
        "id": "2YfEl3cCOtFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"1+1ì€ ì°½ë¬¸ì´ ì•„ë‹ˆê³ ?\"\n",
        "\n",
        "# -- OpenAI Request\n",
        "openai_result = openai_request(user_input=system_prompt)\n",
        "print(f\"# OpenAI Result: {openai_result.content}\")\n",
        "print(\"-\"*20)\n",
        "\n",
        "# # -- Anthropic Request\n",
        "# anthropic_result = anthropic_request(user_input=system_prompt)\n",
        "# print(f\"# Anthropic Result: {anthropic_result[0].text}\")"
      ],
      "metadata": {
        "id": "JrS9yPsAmr3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* gemini ëŠ” system promptê°€ êµ¬ë¶„ë˜ì–´ ìˆì§€ ì•Šì•„, user_inputì— system promptì™€ user inputì„ í•©ì³ì„œ ìš”ì²­í•´ì•¼í•´ìš”.  \n",
        "  * geminiì„ ì‚¬ìš©í•´ì•¼í•˜ë©´ì„œ, system promptì™€ user inputì´ êµ¬ë¶„ë˜ì–´ ìˆë‹¤ë©´ ì•„ë˜ì™€ ê°™ì´ `gemini_propmt_generator()` í•¨ìˆ˜ë¥¼ í†µí•´ì„œ ë‘ ë¬¸ì¥ì„ í•©ì¹˜ê³ \n",
        "  * í•©ì¹œ ë¬¸ì¥ì„ `gemini_request()`ì˜ user_input ê°’ìœ¼ë¡œ ì „ë‹¬í•´ì£¼ì„¸ìš”."
      ],
      "metadata": {
        "id": "AoIJdQeePtAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # -- Gemini Request\n",
        "# system_prompt = \"You're kind ai assistant. Answer in natural korean language.\"\n",
        "# user_input = \"Hi!\"\n",
        "\n",
        "# # geminië¡œ ìš”ì²­ì„ ë³´ë‚´ê¸° ìœ„í•´ ë‘ ë¬¸ì¥ì„ í•©ì¹©ë‹ˆë‹¤.\n",
        "# gemini_prompt = gemini_prompt_generator(system_prompt, user_input)\n",
        "# print(\"-\"*20)\n",
        "# print(f\"# í•©ì³ì§„ ë‘ ë¬¸ì¥ : {gemini_prompt}\")\n",
        "# print(\"-\"*20)\n",
        "\n",
        "# # geminië¡œ requestë¥¼ ë³´ëƒ…ë‹ˆë‹¤.\n",
        "# gemini_result = gemini_request(user_input=gemini_prompt)\n",
        "# print(f\"# Gemini Result: {gemini_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Si6ZwvnKPsTQ",
        "outputId": "a8017f8a-ffaa-476c-8fc6-8310a4ab0969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ë§Œì•½ system promptì™€ user inputì´ êµ¬ë¶„ë˜ì–´ ìˆì§€ ì•Šë‹¤ë©´ ë°”ë¡œ user_inputìœ¼ë¡œ í•´ë‹¹ ê°’ì„ ì „ë‹¬í•˜ì‹œë©´ ë©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "ELI6DM7iSe9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -- Gemini Request\n",
        "system_prompt = \"what is 1+1?\"\n",
        "\n",
        "# geminië¡œ requestë¥¼ ë³´ëƒ…ë‹ˆë‹¤.\n",
        "gemini_result = gemini_request(user_input=system_prompt)\n",
        "print(f\"# Gemini Result: {gemini_result}\")"
      ],
      "metadata": {
        "id": "QhTcyTw0XPOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DeepSeek APIì—ì„œ `deepseek_request()` í•¨ìˆ˜ê°€ `user_input`ì„ í•„ìˆ˜ ì¸ìë¡œ ìš”êµ¬í•˜ê³  ìˆê¸° ë•Œë¬¸ì— ë°œìƒí•˜ëŠ” ë¬¸ì œì…ë‹ˆë‹¤.\n",
        "\n",
        "ì¦‰, `system_prompt`ì™€ `user_input`ì„ ë¶„ë¦¬í•´ì„œ í•¨ìˆ˜ í˜¸ì¶œ ì‹œ ëª¨ë‘ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤. ë§Œì•½ `system_prompt`ë§Œ ì œê³µëœ ìƒí™©ì´ë¼ë©´, `user_input`ì„ ë³„ë„ë¡œ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "0hEHYaloXRoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1ï¸âƒ£ `system_prompt`ì™€ `user_input`ì´ ë‘˜ ë‹¤ ì¡´ì¬í•  ë•Œ"
      ],
      "metadata": {
        "id": "wLhPZjkVn7ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You are a helpful assistant.\"\n",
        "user_input = \"What is 1+1?\"\n",
        "\n",
        "# DeepSeek Request í˜¸ì¶œ\n",
        "deepseek_result = deepseek_request(system_prompt=system_prompt, user_input=user_input)\n",
        "print(f\"# DeepSeek Result: {deepseek_result}\")\n",
        "print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZSKcGqzXSNO",
        "outputId": "dab7f1be-f8e0-4af8-b368-bf46c4a24392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# DeepSeek Result: 1 + 1 equals **2**.\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2ï¸âƒ£ **user_inputì´ ì—†ë‹¤ë©´** `system_prompt`ë¥¼ ê·¸ëŒ€ë¡œ `user_input`ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "99JZBcCGoRGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"1+1ì€ ì°½ë¬¸ì´ ì•„ë‹ˆê³ ?\"\n",
        "user_input = system_prompt\n",
        "\n",
        "# DeepSeek Request í˜¸ì¶œ\n",
        "deepseek_result = deepseek_request(system_prompt=system_prompt, user_input=user_input)\n",
        "print(f\"# DeepSeek Result: {deepseek_result}\")\n",
        "print(\"-\" * 20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3qooNHch4Zk",
        "outputId": "2df72dd8-bc58-4bf5-dbfc-b6c48e2ad560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# DeepSeek Result: 1+1ì€ ìˆ˜í•™ì ìœ¼ë¡œ 2ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. \"1+1ì€ ì°½ë¬¸ì´ ì•„ë‹ˆê³ ?\"ë¼ëŠ” ë§ì€ ìœ ë¨¸ë‚˜ ì–¸ì–´ìœ í¬ë¡œ ë³´ì…ë‹ˆë‹¤. ìˆ«ì '1'ì„ ë‚˜ë€íˆ ë†“ìœ¼ë©´ '11'ì´ ë˜ëŠ”ë°, ì´ë¥¼ ì°½ë¬¸ ëª¨ì–‘ìœ¼ë¡œ ë¹„ìœ í•œ ê²ƒ ê°™ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì—„ë°€íˆ ë§í•˜ë©´ 1+1ì€ 2ì´ë©°, ì°½ë¬¸ê³¼ëŠ” ì§ì ‘ì ì¸ ê´€ë ¨ì´ ì—†ìŠµë‹ˆë‹¤. ì´ í‘œí˜„ì€ ìˆ«ìì˜ ëª¨ì–‘ì„ ì°½ë¬¸ì— ë¹„ìœ í•œ ì¬ë¯¸ìˆëŠ” í‘œí˜„ì¼ ë¿ì…ë‹ˆë‹¤.\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://i.pinimg.com/originals/4f/24/ad/4f24ad648368abd41dc2175aff5dd1a2.gif\" width=200></center>\n",
        "\n",
        "ì—¬ê¸°ê¹Œì§€ê°€ í”„ë¡œì íŠ¸ ì…‹ì—… ê³¼ì •ì— ëŒ€í•œ ì˜¨ë³´ë”©ì´ì—ˆìŠµë‹ˆë‹¤.  \n",
        "ê¸´ ê³¼ì •ì„ ë”°ë¼ì˜¤ì‹œëŠë¼ ìˆ˜ê³ í•˜ì…¨ì–´ìš”! ğŸ‘ğŸ‘ğŸ‘  \n",
        "<br/>\n",
        "\n",
        "ì´ì œ ì§„ì§œ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì´ ì‹œì‘ë©ë‹ˆë‹¤!  \n",
        "ì„¤ë ˆëŠ” ë§ˆìŒìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì„ ì‹œì‘í•˜ëŸ¬ ê°€ë³´ì‹¤ê¹Œìš”? ğŸšŒ =33\n",
        "<br/>\n",
        "<br/>\n"
      ],
      "metadata": {
        "id": "ShNJK5hYS12Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUlMjOr-pnvo"
      },
      "source": [
        "# Prompt Type A: Zero/few/CoT/Zero-shot Cot/Self-consistency\n",
        "------\n",
        "ì˜¤ëŠ˜ ì‹¤ìŠµì—ì„ \n",
        "1. Zero-shot\n",
        "2. Few-shot\n",
        "3. Chain-of-Thought(CoT)\n",
        "4. Zero-shot CoT\n",
        "5. Self-consistency  \n",
        "\n",
        "ê´€ë ¨í•´ì„œ ì‹¤ìŠµì„ ì§„í–‰í•  ì˜ˆì •ì…ë‹ˆë‹¤.\n",
        "ê·¸ëŸ¼ ì²«ë²ˆì§¸ ì‹¤ìŠµ ì£¼ì œë¶€í„° ì‹œì‘í•´ë´…ì‹œë‹¤!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlbwCf04ppig"
      },
      "source": [
        "## 1ï¸âƒ£ Zero-shot prompt engineering\n",
        "---\n",
        "<br/>\n",
        "í”„ë¡¬í”„íŠ¸ ì‘ì„±ì„ í•˜ê¸° ì´ì „ì— `zero-shot`ì— ëŒ€í•´ ê°„ë‹¨íˆ ì•Œì•„ë´…ì‹œë‹¤!\n",
        "<br/>\n",
        "<img src=\"https://drive.google.com/uc?id=1HdA7Lak2yPFkNZeyv3lzjqaZhb8Pvu0W\" alt=\"zero-shot\" width=500>\n",
        "\n",
        "ìœ„ ì´ë¯¸ì§€ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆëŠ” ê²ƒì²˜ëŸ¼, ëª¨ë¸ì—ê²Œ íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ë„ë¡ ìš”ì²­í•  ë•Œ **ì•„ë¬´ëŸ° ì˜ˆì‹œì—†ì´ ì£¼ì–´ì§„ taskë¥¼ ìˆ˜í–‰í•˜ë„ë¡ í•˜ëŠ” ì¼€ì´ìŠ¤**ë¥¼ zero-shotì´ë¼ê³  í•©ë‹ˆë‹¤. ì˜ˆì‹œê°€ ì£¼ì–´ì§€ì§€ ì•ŠëŠ” ëŒ€ì‹  ëª…í™•í•œ ì§€ì‹œë‚˜ ì„¤ëª…ì„ í†µí•´ì„œ ì–´ë–¤ taskë¥¼ ìˆ˜í–‰í•´ì•¼í•˜ëŠ”ì§€ ì´í•´ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.\n",
        "<br/>\n",
        "ì´ ë°©ì‹ì€ ëª¨ë¸ì´ ë§ì€ ë°ì´í„°ë¥¼ í†µí•´ ë‹¤ì–‘í•œ íŒ¨í„´ì„ ìµí˜”ê¸° ë•Œë¬¸ì— ê°€ëŠ¥í•˜ë©°, ìƒˆë¡œìš´ ì‘ì—…ì´ë‚˜ ì§ˆë¬¸ì— ëŒ€í•´ì„œë„ ì‘ë‹µí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
        "<br/>\n",
        "<br/>\n",
        "ê·¸ëŸ¼ ì´ zero-shot promptì˜ ì‹¤ìŠµì„ ì´ì–´ì„œ ì§„í–‰í•´ë´…ì‹œë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `A.1.1` Task 1: Text-classification"
      ],
      "metadata": {
        "id": "AxnPlcJ24ojx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details close>\n",
        "<summary>ğŸ“š prompt ì˜ˆì‹œ (ì˜ì–´)</summary>\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "message = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"Please extract and list each 'Person Name,' and 'email address' in a line.\n",
        "If there is no information, respond with \"N/A\" only. Do not add any additional text.\n",
        "\n",
        "<Text>\n",
        "{{1. \"Hi, I'm John Doe, and you can reach me at [johndoe@example.com](mailto:johndoe@example.com) for any inquiries.\"\n",
        "2. \"Our team lead, Jane Smith ([jane.smith@company.com](mailto:jane.smith@company.com)), will be available for consultation on Monday.\"\n",
        "3. \"Please send the report to the CEO, Mr. Robert Brown, at [email@example.com](mailto:email@example.com).\"\n",
        "4. \"The contact person for the project is Emily Johnson, and her email is [emily.johnson@business.com](mailto:emily.johnson@business.com).\"\n",
        "5. \"For technical support, email our CTO, Alex Taylor, at [firstname.lastname@tech.com](mailto:firstname.lastname@tech.com).\"\n",
        "6. \"The account manager, Sarah Wilson, can be reached at [sarah.wilson@email.com](mailto:sarah.wilson@email.com) for billing questions.\"\n",
        "7. \"Our sales director, Michael Anderson, is available at [firstname.lastname@sales.com](mailto:firstname.lastname@sales.com) for partnership discussions.\"\n",
        "8. \"The HR manager, Lisa Davis, can be contacted at [email@example.com](mailto:email@example.com) for employment opportunities.\"\n",
        "9. \"The lead designer, David Martinez, can be reached at [email@example.com](mailto:email@example.com) for design-related queries.\"\n",
        "10. \"For media inquiries, please contact our PR manager, Olivia Garcia, at [firstname.lastname@pr.com](mailto:firstname.lastname@pr.com).\"}}\n",
        "</Text>\"\"\"\n",
        "    }\n",
        "]\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "ipDVxBNL4bv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details close>\n",
        "<summary>ğŸ“š prompt ì˜ˆì‹œ (í•œê¸€)</summary>\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "message = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"ê° 'ì´ë¦„'ê³¼ 'ì´ë©”ì¼ ì£¼ì†Œ'ë¥¼ í•œ ì¤„ì”© ì¶”ì¶œí•˜ì—¬ ë‚˜ì—´í•´ ì£¼ì„¸ìš”.\n",
        "ì •ë³´ê°€ ì—†ì„ ê²½ìš°, \"N/A\"ë¼ê³ ë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì¶”ê°€ì ì¸ í…ìŠ¤íŠ¸ëŠ” ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”.\n",
        "\n",
        "<Text>\n",
        "{{1. \"ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” John Doeì…ë‹ˆë‹¤. ë¬¸ì˜ì‚¬í•­ì€ [johndoe@example.com](mailto:johndoe@example.com)ìœ¼ë¡œ ì—°ë½ì£¼ì„¸ìš”.\"\n",
        "2. \"ìš°ë¦¬ íŒ€ ë¦¬ë” Jane Smith([jane.smith@company.com](mailto:jane.smith@company.com))ëŠ” ì›”ìš”ì¼ì— ìƒë‹´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\"\n",
        "3. \"CEOì¸ Robert Brown ì”¨ì—ê²Œ ë³´ê³ ì„œë¥¼ [email@example.com](mailto:email@example.com)ìœ¼ë¡œ ë³´ë‚´ì£¼ì„¸ìš”.\"\n",
        "4. \"í”„ë¡œì íŠ¸ ë‹´ë‹¹ìëŠ” Emily Johnsonì´ë©°, ì´ë©”ì¼ì€ [emily.johnson@business.com](mailto:emily.johnson@business.com)ì…ë‹ˆë‹¤.\"\n",
        "5. \"ê¸°ìˆ  ì§€ì›ì€ CTOì¸ Alex Taylorì—ê²Œ [firstname.lastname@tech.com](mailto:firstname.lastname@tech.com)ìœ¼ë¡œ ì´ë©”ì¼ ë³´ë‚´ì£¼ì„¸ìš”.\"\n",
        "6. \"ê³„ì • ë§¤ë‹ˆì € Sarah Wilsonì€ ì²­êµ¬ ê´€ë ¨ ë¬¸ì˜ë¥¼ [sarah.wilson@email.com](mailto:sarah.wilson@email.com)ìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
        "7. \"ì˜ì—… ì´ì‚¬ Michael Andersonì€ íŒŒíŠ¸ë„ˆì‹­ ë…¼ì˜ë¥¼ ìœ„í•´ [firstname.lastname@sales.com](mailto:firstname.lastname@sales.com)ìœ¼ë¡œ ì—°ë½ ê°€ëŠ¥í•©ë‹ˆë‹¤.\"\n",
        "8. \"HR ë§¤ë‹ˆì € Lisa DavisëŠ” ì±„ìš© ê´€ë ¨ ë¬¸ì˜ë¥¼ [email@example.com](mailto:email@example.com)ìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
        "9. \"ìˆ˜ì„ ë””ìì´ë„ˆ David MartinezëŠ” ë””ìì¸ ê´€ë ¨ ì§ˆë¬¸ì„ [email@example.com](mailto:email@example.com)ìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
        "10. \"ë¯¸ë””ì–´ ë¬¸ì˜ëŠ” PR ë§¤ë‹ˆì € Olivia Garciaì—ê²Œ [firstname.lastname@pr.com](mailto:firstname.lastname@pr.com)ìœ¼ë¡œ ì—°ë½ì£¼ì„¸ìš”.\"}}\n",
        "</Text>\"\"\"\n",
        "    }\n",
        "]\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "chgbfp75ecxH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ3jLG0fqyCZ"
      },
      "source": [
        "### `A.1.2` Sentiment Analysis\n",
        "\n",
        "> ğŸ¯ì¡°ê±´: ë¬¸ì¥ì— í•´ë‹¹í•˜ëŠ” ê°ì • ë‹¨ì–´ë§Œ ìƒì„±í•˜ê²Œ í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details close>\n",
        "<summary>ğŸ“š prompt ì˜ˆì‹œ</summary>\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "ğŸ“š\n",
        "prompt ì˜ˆì‹œ:\n",
        "ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê¸ì •, ë¶€ì •, ì¤‘ë¦½ ì¤‘ í•˜ë‚˜ì˜ sentimentë¡œ ë¶„ë¥˜í•´.\n",
        "\n",
        "í…ìŠ¤íŠ¸:\n",
        "- ë‚˜ëŠ” ë§ˆë¼íƒ• ë§›ì´ ê·¸ì € ê·¸ë¬ì–´.\n",
        "- íƒ•í›„ë£¨ë¥¼ ì™œ ë¨¹ëŠ”ì§€ ëª¨ë¥´ê² ì–´.\n",
        "- ìŠ¤íƒ€ë²…ìŠ¤ ê¹ŒëˆŒë ˆ ì°¸ ë§›ìˆë”ë¼.\n",
        "\n",
        "Sentiment:{    }\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "p0grzzgyuDVu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ka0X7W3UpnS-"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê¸ì •, ë¶€ì •, ì¤‘ë¦½ ì¤‘ í•˜ë‚˜ì˜ sentimentë¡œ ë¶„ë¥˜í•´.\"\n",
        "user_input = \"\"\"í…ìŠ¤íŠ¸: ë‚˜ëŠ” ë§ˆë¼íƒ• ë§›ì´ ê·¸ì € ê·¸ë¬ì–´.\n",
        "Sentiment: \"\"\"\n",
        "\n",
        "print(system_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # -- OpenAI Request\n",
        "# openai_result = openai_request(system_prompt=system_prompt,\n",
        "#                         user_input=user_input)\n",
        "# print(f\"# OpenAI Result: {openai_result.content}\")\n",
        "# print(\"-\"*20)\n",
        "\n",
        "# -- Anthropic Request\n",
        "anthropic_result = anthropic_request(system_prompt=system_prompt,\n",
        "                           user_input=user_input)\n",
        "print(f\"# Anthropic Result: {anthropic_result[0].text}\")\n",
        "print(\"-\"*20)\n",
        "\n",
        "\n",
        "# # -- Gemini Request\n",
        "# gemini_result = gemini_request(user_input=f\"{system_prompt}\\n{user_input}\")\n",
        "# print(f\"# Gemini Result: {gemini_result}\")\n",
        "\n",
        "\n",
        "# -- DeepSeek Request\n",
        "# deepseek_result = deepseek_request(system_prompt=system_prompt,\n",
        "#                                    user_input=user_input)\n",
        "# print(f\"# DeepSeek Result: {deepseek_result}\")\n",
        "# print(\"-\" * 20)"
      ],
      "metadata": {
        "id": "tYNHyg0518RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ### `A.1.2` Sentiment Analysis - ğŸ¤– ì‚¬ìš©ìì˜ ê°ì •ì„ íŒŒì•…í•˜ì—¬, ê°ì •ì¼ê¸° ì¨ì£¼ëŠ” ì±—ë´‡"
      ],
      "metadata": {
        "id": "4CYyoHpqpTwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# system_prompt ì •ì˜\n",
        "system_prompt = \"\"\"\n",
        "(ëª¨ë¸ì—ê²Œ ì£¼ì–´ì§„ ì—­í• ê³¼ íƒœë„ë¥¼ ëª…í™•íˆ ì§€ì‹œí•˜ê³ , ìƒì„±í•´ì•¼ í•  ì½˜í…ì¸ ì˜ ëª©ì ê³¼ í˜•ì‹ì„ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.)\n",
        "\"\"\"\n",
        "\n",
        "# user_input ì˜ˆì œ\n",
        "user_input = \"\"\"\n",
        "(ê°„ë‹¨í•˜ê³  ëª…í™•í•œ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­ì„ ì‘ì„±í•˜ì„¸ìš”.)\n",
        "\"\"\"\n",
        "\n",
        "# OpenAI API í˜¸ì¶œ\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_input},\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "result = response['choices'][0]['message']['content']\n",
        "print(\"ëª¨ë¸ì˜ ì‘ë‹µ:\\n\", result)\n"
      ],
      "metadata": {
        "id": "93kk7FSGvxdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgR-GJ3NwsLH"
      },
      "source": [
        "### `A.1.3` Task 2: Translation_a\n",
        "\n",
        "> ğŸ¯ ì œì‘ ì¡°ê±´:\n",
        "  1. í…ìŠ¤íŠ¸ì—ì„œ ê¸°ìˆ  ìš©ì–´ëŠ” ì›ë¬¸ì˜ ì˜ì–´ë¥¼ ì‚´ë ¤, ì˜ì–´(í•œêµ­ì–´ ëœ») ì´ ë‚˜ì˜¤ê²Œ í•˜ê¸°\n",
        "  2. ê¸°ìˆ  ìš©ì–´ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ê¸°\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details close>\n",
        "<summary>ğŸ“š prompt ì˜ˆì‹œ</summary>\n",
        "\n",
        "\n",
        "```\n",
        "ğŸ“š\n",
        "prompt ì˜ˆì‹œ:\n",
        "Translate the following text from <English to Korean>. Observe the rules when translating. SHOULD Leave technical words in English with the Korean translation in parentheses ( ), English(Korean Translation).\n",
        "\n",
        "- Text: The o1 model series is trained with large-scale reinforcement learning to reason using chain of thought. These advanced reasoning capabilities provide new avenues for improving the safety and robustness of our models. In particular, our models can reason about our safety policies in context when responding to potentially unsafe prompts. This leads to state-of-the-art performance on certain benchmarks for risks such as generating illicit advice, choosing stereotyped responses, and succumbing to known jailbreaks. Training models to incorporate a chain of thought before answering has the potential to unlock substantial benefits, while also increasing potential risks that stem from heightened intelligence. Our results underscore the need for building robust alignment methods, extensively stress-testing their efficacy, and maintaining meticulous risk management protocols. This report outlines the safety work carried out for the OpenAI o1-preview and OpenAI o1-mini models, including safety evaluations, external red teaming, and Preparedness Framework evaluations.\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "Ehn8auv-wzDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"(ì—¬ê¸°ì— í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”)\"\n",
        "\n",
        "user_input = \"\"\"The o1 model series is trained with large-scale reinforcement learning to reason using chain of thought. These advanced reasoning capabilities provide new avenues for improving the safety and robustness of our models. In particular, our models can reason about our safety policies in context when responding to potentially unsafe prompts. This leads to state-of-the-art performance on certain benchmarks for risks such as generating illicit advice, choosing stereotyped responses, and succumbing to known jailbreaks. Training models to incorporate a chain of thought before answering has the potential to unlock substantial benefits, while also increasing potential risks that stem from heightened intelligence. Our results underscore the need for building robust alignment methods, extensively stress-testing their efficacy, and maintaining meticulous risk management protocols. This report outlines the safety work carried out for the OpenAI o1-preview and OpenAI o1-mini models, including safety evaluations, external red teaming, and Preparedness Framework evaluations.\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TXYM7nm-x2E2",
        "outputId": "c3d1527e-a4fb-4104-ac16-9cfcaddc5260",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -- OpenAI Request\n",
        "openai_result = openai_request(system_prompt=system_prompt,\n",
        "                        user_input=user_input)\n",
        "print(f\"# OpenAI Result: {openai_result.content}\")\n",
        "print(\"-\"*20)\n",
        "\n",
        "# # -- Anthropic Request\n",
        "# anthropic_result = anthropic_request(system_prompt=system_prompt,\n",
        "#                            user_input=user_input)\n",
        "# print(f\"# Anthropic Result: {anthropic_result[0].text}\")\n",
        "# print(\"-\"*20)\n",
        "\n",
        "\n",
        "# # -- Gemini Request\n",
        "# gemini_result = gemini_request(user_input=f\"{system_prompt}\\n{user_input}\")\n",
        "# print(f\"# Gemini Result: {gemini_result}\")\n",
        "\n",
        "\n",
        "# -- DeepSeek Request\n",
        "# deepseek_result = deepseek_request(system_prompt=system_prompt,\n",
        "#                                    user_input=user_input)\n",
        "# print(f\"# DeepSeek Result: {deepseek_result}\")\n",
        "# print(\"-\" * 20)"
      ],
      "metadata": {
        "id": "DgDdvoyc1Nmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `A.1.3` Task 3: Translation_b"
      ],
      "metadata": {
        "id": "2S6hp0V7qRWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejVAFXAPnOw6",
        "outputId": "6c001233-9461-48a5-ae05-3352d979648f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "from google.colab import files\n",
        "\n",
        "def read_pdf(file_path):\n",
        "    \"\"\"PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\"\"\"\n",
        "    text = \"\"\n",
        "    with open(file_path, 'rb') as f:\n",
        "        for page in PyPDF2.PdfReader(f).pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def process_pdf_with_models():\n",
        "    \"\"\"PDF ì—…ë¡œë“œ ë° ëª¨ë¸ í˜¸ì¶œ\"\"\"\n",
        "    # PDF ì—…ë¡œë“œ\n",
        "    uploaded = files.upload()\n",
        "    for name in uploaded.keys():\n",
        "        content = read_pdf(name)\n",
        "        print(\"\\nPDF ë‚´ìš©:\")\n",
        "        print(content)\n",
        "\n",
        "        # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì…ë ¥\n",
        "        task = input(\"\\ní”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”: \")\n",
        "        user_input = f\"{task}: {content}\"\n",
        "\n",
        "        # OpenAI ìš”ì²­\n",
        "        system_prompt = \"ë‹¤ìŒ ìš”ì²­ì„ ì²˜ë¦¬í•˜ì„¸ìš”.\"\n",
        "        openai_result = openai_request(\n",
        "            system_prompt=system_prompt,\n",
        "            user_input=user_input\n",
        "        )\n",
        "        print(f\"# OpenAI Result:\\n{openai_result.content}\")\n",
        "        print(\"-\" * 20)\n",
        "\n",
        "# ì‹¤í–‰\n",
        "process_pdf_with_models()\n"
      ],
      "metadata": {
        "id": "XuRuLsFlWnsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- OpenAI Request\n",
        "openai_result = openai_request(system_prompt=system_prompt,\n",
        "                        user_input=user_input)\n",
        "print(f\"# OpenAI Result: {openai_result.content}\")\n",
        "print(\"-\"*20)\n",
        "\n",
        "# # -- Anthropic Request\n",
        "# anthropic_result = anthropic_request(system_prompt=system_prompt,\n",
        "#                            user_input=user_input)\n",
        "# print(f\"# Anthropic Result: {anthropic_result[0].text}\")\n",
        "# print(\"-\"*20)\n",
        "\n",
        "\n",
        "# # -- Gemini Request\n",
        "# gemini_result = gemini_request(user_input=f\"{system_prompt}\\n{user_input}\")\n",
        "# print(f\"# Gemini Result: {gemini_result}\")\n",
        "\n",
        "\n",
        "# -- DeepSeek Request\n",
        "# deepseek_result = deepseek_request(system_prompt=system_prompt,\n",
        "#                                    user_input=user_input)\n",
        "# print(f\"# DeepSeek Result: {deepseek_result}\")\n",
        "# print(\"-\" * 20)"
      ],
      "metadata": {
        "id": "QzDlNOs3nFM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `A.1.3` Task 3: FAQs ìƒì„±ê¸° ë§Œë“¤ê¸°  \n",
        "ì‚¬ìš©ì ì…ë ¥ê°’ (User query) ì— ê¸°ë°˜í•´ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸(FAQs) ë§Œë“¤ê¸°\n",
        "\n",
        "> ğŸ¯ì œì‘ ì¡°ê±´:\n",
        "\n",
        "1. ëª¨ë°”ì¼ ì•± í™˜ê²½ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ì¶œë ¥ë¬¼ ê¸¸ì´ ì¡°ì ˆí•˜ê¸° (ì§§ê²Œ)\n",
        "2. ì‚¬ìš©ìê°€ í¥ë¯¸ë¥¼ ê°€ì§€ê³  Multi-turn ëŒ€í™”ë¥¼ í•  ìˆ˜ ìˆë„ë¡ ìœ ë„í•˜ëŠ” ë‚´ìš©ì˜ ì§ˆë¬¸ ì œì‘í•˜ê¸°\n",
        "3. ì‚¬ìš©ìì˜ ì…ë ¥ê°’ê³¼ ì—°ê´€ìˆëŠ” ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ ì œì‘í•˜ê¸°"
      ],
      "metadata": {
        "id": "SlLWg1pz2X6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details close>\n",
        "<summary>ğŸ“š prompt ì˜ˆì‹œ</summary>\n",
        "\n",
        "\n",
        "```\n",
        "ğŸ“š\n",
        "prompt ì˜ˆì‹œ:\n",
        "# [Introduction]\n",
        "You have a mind and your role is to generate possible three questions a user maywant to ask next based on {{$User input: ì œì£¼ë„ ê°ê·¤ ì´ˆì½œë¦¿ì€ ì–¼ë§ˆì•¼?}}\n",
        "Thequestions must be from the perspective of me, the user asking you a question.\n",
        "## [Response template]Predicted user question as followed:High certaintyModerate certainty, yet intriguingLow certainty, but strong potential for user engagement\n",
        "### [Ending]Answer in half-speech form of Korean(ë°˜ë§). Donâ€™t be over five words. Only providethree questions.\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "--qpQAe627vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -- âŒ ì´ ì½”ë“œì…€ì€ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”\n",
        "system_prompt = \"\"\"(ì—¬ê¸°ì— í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”)\"\"\"\n"
      ],
      "metadata": {
        "id": "QY-PJUr21YS9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "dc010cfc-63ac-4cb6-a7a4-f8dc3d27a6b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(system_prompt)"
      ],
      "metadata": {
        "id": "vYAbpZH915Xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- OpenAI Request\n",
        "openai_result = openai_request(user_input=system_prompt)\n",
        "print(f\"# OpenAI Result: {openai_result.content}\")\n",
        "print(\"-\"*20)\n",
        "\n",
        "# # -- Anthropic Request\n",
        "# anthropic_result = anthropic_request(user_input=system_prompt)\n",
        "# print(f\"# Anthropic Result: {anthropic_result[0].text}\")\n",
        "# print(\"-\"*20)\n",
        "\n",
        "\n",
        "# # -- Gemini Request\n",
        "# gemini_result = gemini_request(user_input=system_prompt)\n",
        "# print(f\"# Gemini Result: {gemini_result}\")\n",
        "\n",
        "\n",
        "# -- DeepSeek Request\n",
        "# deepseek_result = deepseek_request(system_prompt=system_prompt,\n",
        "#                                    user_input=user_input)\n",
        "# print(f\"# DeepSeek Result: {deepseek_result}\")\n",
        "# print(\"-\" * 20)"
      ],
      "metadata": {
        "id": "hTxDddTBzSEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "<br/>"
      ],
      "metadata": {
        "id": "0kCztTmDnf5j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2ï¸âƒ£ Few-shot prompt engineering\n",
        "---\n",
        "<br/>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1LcXS249ywbbqYp2Fvk2gAnhmjfFzUv2R\" alt=\"few-shot learning\" width=\"500\"/>\n",
        "\n",
        "ì´ë²ˆì—” Few-shotì— ëŒ€í•´ ì•Œì•„ë´…ì‹œë‹¤.  \n",
        "zero-shotì´ task descriptionë§Œìœ¼ë¡œ êµ¬ì„±ëœ ì¼€ì´ìŠ¤ë¼ë©´, Few-shotì€ ì´ë¦„ì—ì„œ ì§ì‘í•  ìˆ˜ ìˆë“¯ì´ **ëª‡ ê°€ì§€ ì˜ˆì‹œ**ë¥¼ ì œê³µí•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì´ ì˜ˆì‹œë“¤ì„ í†µí•´ ëª¨ë¸ì€ ì–´ë–¤ íŒ¨í„´ì„ ë”°ë¥´ê¸¸ ì›í•˜ëŠ”ì§€ íŒíŠ¸ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•´ê²°í•˜ê¸° ì–´ë ¤ìš´ ì‘ì—…ì´ë‚˜ íŠ¹ì •í•œ í˜•ì‹ì˜ ì¶œë ¥ì„ ìš”êµ¬í•˜ëŠ” ê²½ìš°ì— ìœ ìš©í•©ë‹ˆë‹¤.\n",
        "<br/>\n",
        "<br/>\n",
        "ê·¸ëŸ¼ ì´ few-shot promptì˜ ì‹¤ìŠµì„ ì´ì–´ì„œ ì§„í–‰í•´ë´…ì‹œë‹¤."
      ],
      "metadata": {
        "id": "skvL2CW1n0NG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `A.2.1` Task 1: ìƒì†Œí•œ ë‹¨ì–´ë¥¼ ì°¾ëŠ” í”„ë¡¬í”„íŠ¸ ì‘ì„±í•˜ê¸°\n",
        "\n",
        "> ğŸ’« ëª©í‘œ: ë‹¨ì–´ â€˜whatpuâ€™ ì™€ â€˜farduddleâ€™ì˜ ì˜ë¯¸ë¥¼ ì°¾ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ í“¨ì‚¿ì„ ì‚¬ìš©í•˜ì—¬ ì‘ì„±í•˜ê¸°\n",
        "<br/>\n",
        "> ğŸ“‘ ì¶œë ¥ í˜•íƒœ: `ë‹¨ì–´: ëœ», ì˜ˆì‹œ ë¬¸ì¥`\n"
      ],
      "metadata": {
        "id": "hN31zL4Sr8Jg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details close>\n",
        "<summary>ğŸ“š prompt ì˜ˆì‹œ</summary>\n",
        "\n",
        "\n",
        "```\n",
        "ğŸ“š\n",
        "prompt ì˜ˆì‹œ:\n",
        "\n",
        "A \"whatpu\" is a small, furry animal native to Tanzania.\n",
        "An example of a sentence that uses the word whatpu is:\n",
        "We were traveling in Africa and we saw these very cute whatpus.\n",
        "\n",
        "-\"farduddle\" means:\n",
        "-An example of a sentence that uses the word farduddle is:\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "bKZrNokCshCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\" (ì—¬ê¸°ì— í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”)\"\"\"\n"
      ],
      "metadata": {
        "id": "-g_2khcisort"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(system_prompt)"
      ],
      "metadata": {
        "id": "0lEKGfUEsor2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- A.2ë¶€í„°ëŠ” ì§ì ‘ api request í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ë³´ì„¸ìš”! ì´ì „ A.1ì—ì„œ ì‚¬ìš©í•œ ì½”ë“œë¥¼ ì°¸ê³ í•˜ì‹œë©´ ë©ë‹ˆë‹¤!"
      ],
      "metadata": {
        "id": "OGxD122nsor3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "<br/>"
      ],
      "metadata": {
        "id": "0oHXkdoXs8e1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3ï¸âƒ£ Chain-of-thought prompting\n",
        "---\n",
        "<br/>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=13WioB9chHs5hu0pxvnqpdGEI17j6HQ29\" alt=\"Chain-of-thought\" width=\"500\"/>\n",
        "\n",
        "ì´ë²ˆì—” Chain of Thought(CoT)ì— ëŒ€í•´ ì•Œì•„ë´…ì‹œë‹¤. CoTëŠ” ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•  ë•Œ ë‹¨ê³„ë³„ë¡œ ì‚¬ê³  ê³¼ì •ì„ ë”°ë¼ê°€ë„ë¡ í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì´ ë°©ë²•ë¡ ì€ ëª¨ë¸ì´ ë‹µì„ ë‹¨ìˆœíˆ ë°”ë¡œ ë‚´ë†“ëŠ” ëŒ€ì‹ ì—, ë¬¸ì œë¥¼ í’€ê¸° ìœ„í•´ í•„ìš”í•œ ì¤‘ê°„ ë‹¨ê³„ë“¤ì„ ëª…ì‹œì ìœ¼ë¡œ ìƒê°í•˜ë„ë¡ í•˜ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤.\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "ê·¸ëŸ¼ ì´ Chain of Thought(CoT)ì˜ ì‹¤ìŠµì„ ì´ì–´ì„œ ì§„í–‰í•´ë´…ì‹œë‹¤."
      ],
      "metadata": {
        "id": "jlGx98LRKJ8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `A.3.1` Task 1: ë‹¤ìŒ ìˆ˜í•™ ë¬¸ì œë¥¼ Chain-of-thought ê¸°ë²•ì„ ì´ìš©í•´ ì •ë‹µì„ í’€ì´í•´ë³´ì„¸ìš”\n",
        "\n"
      ],
      "metadata": {
        "id": "mwelei_-LWor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ğŸ¯ì¡°ê±´: CoT ë°©ë²•ë¡ ì„ í™œìš©í•´ì„œ ì•„ë˜ ë¬¸ì œì˜ ë‹µì„ êµ¬í•˜ê¸°\n",
        "\n",
        "```\n",
        "ì´ ê·¸ë£¹ì˜ í™€ìˆ˜ë“¤ì„ ë”í•˜ë©´ ì§ìˆ˜ê°€ ë©ë‹ˆë‹¤: 4, 8, 9, 15, 12, 2, 1.\n",
        "ë‹µ: ê±°ì§“ì…ë‹ˆë‹¤.\n",
        "ì´ ê·¸ë£¹ì˜ í™€ìˆ˜ë“¤ì„ ë”í•˜ë©´ ì§ìˆ˜ê°€ ë©ë‹ˆë‹¤: 17, 10, 19, 4, 8, 12, 24.\n",
        "ë‹µ: ì°¸ì…ë‹ˆë‹¤.\n",
        "ì´ ê·¸ë£¹ì˜ í™€ìˆ˜ë“¤ì„ ë”í•˜ë©´ ì§ìˆ˜ê°€ ë©ë‹ˆë‹¤: 16, 11, 14, 4, 8, 13, 24.\n",
        "ë‹µ: ì°¸ì…ë‹ˆë‹¤.\n",
        "ì´ ê·¸ë£¹ì˜ í™€ìˆ˜ë“¤ì„ ë”í•˜ë©´ ì§ìˆ˜ê°€ ë©ë‹ˆë‹¤: 17, 9, 10, 12, 13, 4, 2.\n",
        "ë‹µ: ê±°ì§“ì…ë‹ˆë‹¤.\n",
        "ì´ ê·¸ë£¹ì˜ í™€ìˆ˜ë“¤ì„ ë”í•˜ë©´ ì§ìˆ˜ê°€ ë©ë‹ˆë‹¤: 15, 32, 5, 13, 82, 7, 1.\n",
        "ë‹µ:\n",
        "```"
      ],
      "metadata": {
        "id": "z_yQwvO0Lvcg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details close>\n",
        "<summary>ğŸ“š prompt ì˜ˆì‹œ</summary>\n",
        "\n",
        "\n",
        "```\n",
        "ğŸ“š\n",
        "prompt ì˜ˆì‹œ:\n",
        "\n",
        "ì´ ê·¸ë£¹ì˜ í™€ìˆ˜ì˜ í•©ì´ ì§ìˆ˜ê°€ ëœë‹¤: 4, 8, 9, 15, 12, 2, 1.\n",
        "A: ëª¨ë“  í™€ìˆ˜(9, 15, 1)ë¥¼ ë”í•˜ë©´ 25ì…ë‹ˆë‹¤.\n",
        "ì •ë‹µì€ \"ê±°ì§“\"ì…ë‹ˆë‹¤.\n",
        "ì´ ê·¸ë£¹ì˜ í™€ìˆ˜ì˜ í•©ì´ ì§ìˆ˜ê°€ ëœë‹¤: 17, 10, 19, 4, 8, 12, 24.\n",
        "A: ëª¨ë“  í™€ìˆ˜(17, 19)ë¥¼ ë”í•˜ë©´ 36ì…ë‹ˆë‹¤.\n",
        "ì •ë‹µì€ \"ì°¸\"ì…ë‹ˆë‹¤.\n",
        "ì´ ê·¸ë£¹ì˜ í™€ìˆ˜ì˜ í•©ì´ ì§ìˆ˜ê°€ ëœë‹¤: 16, 11, 14, 4, 8, 13, 24.\n",
        "A: ëª¨ë“  í™€ìˆ˜(11, 13)ë¥¼ ë”í•˜ë©´ 24ì…ë‹ˆë‹¤.\n",
        "ì •ë‹µì€ \"ì°¸\"ì…ë‹ˆë‹¤.\n",
        "ì´ ê·¸ë£¹ì˜ í™€ìˆ˜ì˜ í•©ì´ ì§ìˆ˜ê°€ ëœë‹¤: 17, 9, 10, 12, 13, 4, 2.\n",
        "A: ëª¨ë“  í™€ìˆ˜(17, 9, 13)ë¥¼ ë”í•˜ë©´ 39ì…ë‹ˆë‹¤.\n",
        "ì •ë‹µì€ \"ê±°ì§“\"ì…ë‹ˆë‹¤.\n",
        "ì´ ê·¸ë£¹ì˜ í™€ìˆ˜ì˜ í•©ì´ ì§ìˆ˜ê°€ ëœë‹¤: 15, 32, 5, 13, 82, 7, 1.\n",
        "A:\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "oqAPL3XNLh4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"ì—¬ê¸°ì— ì‘ì„±í•œ promptë¥¼ ì…ë ¥í•˜ì„¸ìš”\"\"\""
      ],
      "metadata": {
        "id": "ZDtwH78eLfe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(system_prompt)"
      ],
      "metadata": {
        "id": "nPOe-g7lMicX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- api request í•¨ìˆ˜ ìš”ì²­ ì½”ë“œ ì‘ì„±í•˜ê¸°"
      ],
      "metadata": {
        "id": "IoOkJGw4MicX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "<br/>"
      ],
      "metadata": {
        "id": "2TkYWcTfM455"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `A.3.2` Task 2: Chain-of-thought ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì˜ì–´ í•™ìŠµ ì±—ë´‡ ë§Œë“¤ê¸°\n",
        "\n",
        "> âœï¸ ìƒí™©: ì˜ì–´ í™”ìê°€ í•œêµ­ì–´ë¥¼ ì•±ì„ í†µí•´ í•™ìŠµí•˜ëŠ” ìƒí™©ì…ë‹ˆë‹¤. Intermediate levelì˜ ìˆ˜ê°•ìƒì…ë‹ˆë‹¤.\n",
        "\n",
        "í•™ìƒì˜ ì´ë¦„ì€ Davidì´ê³ , í•™ìŠµ ì£¼ì œëŠ” â€œë§ˆì¼€íŒ… ì „ëµ ë…¼ì˜í•˜ê¸°â€ ì…ë‹ˆë‹¤.  \n",
        "í•™ìŠµí•´ì•¼ í•˜ëŠ” ë‹¨ì–´ëŠ” : Strategy, target, analysis ì…ë‹ˆë‹¤.\n",
        "<br/>\n",
        "<br/>\n",
        "> ğŸ¯ ì¡°ê±´: 1~3ë‹¨ê³„ê°€ í•œ í”„ë¡¬í”„íŠ¸ ì•ˆì— ë‹´ê²¨ì„œ, í•´ë‹¹ ë‚´ìš©ì´ step-by-step í•  ìˆ˜ìˆë„ë¡ ì„¤ê³„ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "- 1ë‹¨ê³„: ê° ë‹¨ì–´ì˜ ëœ»ì„ ê°€ë¥´ì³ì£¼ëŠ” ì±—ë´‡ì„ ë§Œë“œì„¸ìš”.\n",
        "- 2ë‹¨ê³„: ê° ë‹¨ì–´ë¥¼ ë”°ë¼ ì½ë„ë¡í•˜ê³ , David ì—ê²Œ ì˜ˆì‹œ ë¬¸ì¥ì„ ë§Œë“¤ì–´ë³´ë¼ê³  í•˜ì„¸ìš”. ì„¸ ë‹¨ì–´ ë°˜ë³µí•´ì£¼ì„¸ìš”\n",
        "- 3ë‹¨ê³„: David ì´ ì˜ë”°ë¼í•œë‹¤ë©´ ì¹­ì°¬ì„ í•´ì£¼ê³ , ì˜ ë”°ë¼ì˜¤ì§€ ëª»í•œë‹¤ë©´ guide ë¥¼ ì£¼ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì œì‘í•˜ì„¸ìš”."
      ],
      "metadata": {
        "id": "BqS8SWLGNEcz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details close>\n",
        "<summary>ğŸ“š prompt ì˜ˆì‹œ</summary>\n",
        "\n",
        "\n",
        "```\n",
        "ğŸ“š\n",
        "prompt ì˜ˆì‹œ:\n",
        "\n",
        "prompt ì œëª©:\n",
        "Generate Lesson from unit & lesson title\n",
        "\n",
        "\n",
        "Prompt:\n",
        "\n",
        "AI Tutor Role\n",
        "=============\n",
        "You are an AI Korean language tutor for David, an intermediate English speaker. Your primary goal is to facilitate David's learning through interactive, adaptive conversation. Always wait for David's input before proceeding.\n",
        "\n",
        "Key Guidelines\n",
        "--------------\n",
        "0. Please list out all the target words at first.  \n",
        "1. Use beginner-level Korean language. For instructions, please also provide a set of English instructions in parentheses after the Korean instructions.\n",
        "2. Encourage David to speak more than you do.\n",
        "3. Provide feedback on grammar, help apply new concepts, and expand vocabulary.\n",
        "4. Adapt your teaching style based on David's responses and progress.\n",
        "5. Use Korean for target vocabulary and example sentences. Use English for explanations and instructions.\n",
        "Lesson Focus\n",
        "------------\n",
        "**Topic:** \"ë§ˆì¼€íŒ… ì „ëµ ë…¼ì˜í•˜ê¸°\" (Discussing Marketing Strategies)\n",
        "**Target Vocabulary:**\n",
        "- ì „ëµ (strategy)\n",
        "- íƒ€ê²Ÿ (target)\n",
        "- ë¶„ì„ (analysis)\n",
        "Interaction Flow\n",
        "----------------\n",
        ".. Pause for user input after each step.\n",
        "1. Introduce one target word at a time.\n",
        "2. Ask David to repeat the word.\n",
        "5. Explain the word's meaning and usage in English.\n",
        "3. Provide an example sentence in Korean.\n",
        "4. Ask David to repeat the English sentence.\n",
        "6. Prompt David to create his own sentence using the word.\n",
        "7. Provide feedback in Korean on David's sentence.\n",
        "8. Move to the next word only after David demonstrates understanding.\n",
        "\n",
        "Adaptive Teaching\n",
        "-----------------\n",
        "- If David struggles: Offer simpler explanations or additional examples.\n",
        "- If David excels: Introduce more complex usage or related vocabulary.\n",
        "Conversation Practice\n",
        "------------------\n",
        "After introducing all words:\n",
        "1. Initiate a conversation about marketing strategies in Korean.\n",
        "2. Encourage David to use the new vocabulary.\n",
        "3. Provide real-time feedback on grammar and usage.\n",
        "Lesson Conclusion\n",
        "-----------------\n",
        "1. Ask David to summarize what he's learned.\n",
        "2. Provide final feedback on his progress.\n",
        "3. Call the finish_class function only when David has successfully used all key vocabulary words in conversation and demonstrated understanding of their usage.\n",
        "Remember: Your responses should be brief and always end with a question or prompt for David. Do not generate David's responses or proceed without his input.\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "TSBBU740NEc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\" (ì—¬ê¸°ì— í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”) \"\"\""
      ],
      "metadata": {
        "id": "B7eA1BaHNEc-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0ba2ebcb-22f4-443d-88db-279dcf2112e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸(Multi-Turn ë²„ì „)\n",
        "client = LLMClient()  # â†-ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”.\n",
        "\n",
        "model_config = {\n",
        "    # â†“ ì—¬ê¸°ì—ì„œ ë§¤ê°œë³€ìˆ˜ ê°’ì„ ì„¤ì •í•˜ì„¸ìš”.\n",
        "    \"system_prompt\": system_prompt,\n",
        "}\n",
        "\n",
        "while True:\n",
        "    user_prompt = input(\"prompt : \").strip()\n",
        "    if (\"q\" or \"quite\") in user_prompt:\n",
        "        print(\"Bye\")\n",
        "        break\n",
        "\n",
        "    response = client.get_completion(prompt=user_prompt, multi=True, **model_config)\n",
        "    print(response, '\\n')"
      ],
      "metadata": {
        "id": "im4tBq3sLBnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- A.2ë¶€í„°ëŠ” ì§ì ‘ api request í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ë³´ì„¸ìš”! ì´ì „ A.1ì—ì„œ ì‚¬ìš©í•œ ì½”ë“œë¥¼ ì°¸ê³ í•˜ì‹œë©´ ë©ë‹ˆë‹¤!\n",
        "# -- OpenAI Request\n",
        "openai_result = openai_request(user_input=system_prompt)\n",
        "print(f\"# OpenAI Result: {openai_result.content}\")\n",
        "print(\"-\"*20)\n",
        "\n",
        "# # -- Anthropic Request\n",
        "# anthropic_result = anthropic_request(user_input=system_prompt)\n",
        "# print(f\"# Anthropic Result: {anthropic_result[0].text}\")\n",
        "# print(\"-\"*20)\n",
        "\n",
        "\n",
        "# # -- Gemini Request\n",
        "# gemini_result = gemini_request(user_input=system_prompt)\n",
        "# print(f\"# Gemini Result: {gemini_result}\")\n",
        "\n",
        "\n",
        "# -- DeepSeek Request\n",
        "# deepseek_result = deepseek_request(system_prompt=system_prompt,\n",
        "#                                    user_input=user_input)\n",
        "# print(f\"# DeepSeek Result: {deepseek_result}\")\n",
        "# print(\"-\" * 20)"
      ],
      "metadata": {
        "id": "H4gahR9pNEc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "<br/>"
      ],
      "metadata": {
        "id": "HqloOA2RNEc-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4ï¸âƒ£ Zero-shot Cot\n",
        "---\n",
        "<br/>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1BlO4s4W6V3vkAWSERHeC2XHIDghQyxTJ\" alt=\"Zero-shot CoT\" width=\"500\"/>\n",
        "\n",
        "zero-shot chain of thought promptingì€ ì¼ë°˜ì ì¸ CoT promptingì˜ ë³€í˜•ìœ¼ë¡œ ëª¨ë¸ì´ ëª…ì‹œì ì¸ ì˜ˆì‹œë‚˜ ì§€ì‹œ ì—†ì´ë„ ë³µì¡í•œ ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ í’€ë„ë¡ ìœ ë„í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ë§Œìœ¼ë¡œ ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ ì‚¬ê³  ê³¼ì •ì„ í†µí•´ ë‹µì„ ë„ì¶œí•˜ê²Œ í•˜ëŠ” ë°©ë²•ë¡ ì…ë‹ˆë‹¤.\n",
        "<br/>\n",
        "<br/>\n",
        "Zero-shot CoT ì‹¤ìŠµì„ ì§„í–‰í•´ë´…ì‹œë‹¤!"
      ],
      "metadata": {
        "id": "QX9ifj8uPROx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `A.4.1` Zero-shot CoTë¥¼ í™œìš©í•œ ìˆ˜í•™ë¬¸ì œ í’€ì´\n",
        "\n"
      ],
      "metadata": {
        "id": "GpJdthAePYl8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ğŸ§— Step 1. ìˆ˜í•™ ë¬¸ì œë¥¼ Zero-shot CoTë¥¼ ì‚¬ìš©í•´ì„œ ë¬¸ì œë¥¼ í’€ì–´ë³´ì„¸ìš”.\n",
        "\n",
        "```\n",
        "ğŸ“Œ ë¬¸ì œ\n",
        "\n",
        "ì €ëŠ” ì‹œì¥ì— ê°€ì„œ ì‚¬ê³¼ 10ê°œë¥¼ ìƒ€ìŠµë‹ˆë‹¤.\n",
        "ì´ì›ƒì—ê²Œ ì‚¬ê³¼ 2ê°œë¥¼ ì£¼ê³  ê°•ì•„ì§€ì—ê²Œë„ 2ê°œë¥¼ ì¤¬ìŠµë‹ˆë‹¤.\n",
        "ê·¸ë¦¬ê³  ë‚˜ì„œ 5ê°œì˜ ì‚¬ê³¼ë¥¼ ë” ì‚¬ì„œ 1ê°œë¥¼ ë¨¹ì—ˆìŠµë‹ˆë‹¤.\n",
        "ì œê°€ ê°€ì§„ ì‚¬ê³¼ëŠ” ëª‡ ê°œê°€ ë‚¨ì•˜ë‚˜ìš”?\n",
        "```"
      ],
      "metadata": {
        "id": "pLDoez32PYl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details close>\n",
        "<summary>ğŸ“š prompt ì˜ˆì‹œ</summary>\n",
        "\n",
        "\n",
        "```\n",
        "ğŸ“š\n",
        "prompt ì˜ˆì‹œ:\n",
        "\n",
        "ì €ëŠ” ì‹œì¥ì— ê°€ì„œ ì‚¬ê³¼ 10ê°œë¥¼ ìƒ€ìŠµë‹ˆë‹¤. ì´ì›ƒì—ê²Œ ì‚¬ê³¼ 2ê°œë¥¼ ì£¼ê³  ê°•ì•„ì§€ì—ê²Œë„ 2ê°œë¥¼ ì¤¬ìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ë‚˜ì„œ 5ê°œì˜ ì‚¬ê³¼ë¥¼ ë” ì‚¬ì„œ 1ê°œë¥¼ ë¨¹ì—ˆìŠµë‹ˆë‹¤. ì œê°€ ê°€ì§„ ì‚¬ê³¼ëŠ” ëª‡ ê°œê°€ ë‚¨ì•˜ë‚˜ìš”?  \n",
        "Let's think step by step.\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "BRkmwV2IPYl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"ì—¬ê¸°ì— ì‘ì„±í•œ promptë¥¼ ì…ë ¥í•˜ì„¸ìš”\"\"\""
      ],
      "metadata": {
        "id": "EA_TeMWrRiiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(system_prompt)"
      ],
      "metadata": {
        "id": "aEHLFJNBRiiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- api request í•¨ìˆ˜ ìš”ì²­ ì½”ë“œ ì‘ì„±í•˜ê¸°"
      ],
      "metadata": {
        "id": "PwdbK64oRiiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "<br/>"
      ],
      "metadata": {
        "id": "SNBtl85VRtbu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ğŸ§— Step 2. `Think step by ste`p ì´ ì•„ë‹Œ ìì‹  ë§Œì˜ Trigger ë¬¸ì¥ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”. ì˜ˆì‹œì˜ Trigger Example ì„ ì°¸ê³ í•´ë„ ë©ë‹ˆë‹¤. Prompt ì˜ ê²°ê³¼ë¥¼ A/B ë¹„êµí•´ë³´ì„¸ìš”.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1XVDaU7Bw0G3pnI47C3afftd-sbaQdTwG\" alt=\"Zero-shot CoT\" width=\"500\"/>\n"
      ],
      "metadata": {
        "id": "E29oiqU5RxRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"ì—¬ê¸°ì— ì‘ì„±í•œ promptë¥¼ ì…ë ¥í•˜ì„¸ìš”\"\"\""
      ],
      "metadata": {
        "id": "eusCyTjvPYl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(system_prompt)"
      ],
      "metadata": {
        "id": "A6of_xDTPYl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- api request í•¨ìˆ˜ ìš”ì²­ ì½”ë“œ ì‘ì„±í•˜ê¸°"
      ],
      "metadata": {
        "id": "d0kCPWTRPYl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "<br/>"
      ],
      "metadata": {
        "id": "8JYxKHmbPYl-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5ï¸âƒ£ Self-Consistency Prompt Engineering\n",
        "---\n",
        "<br/>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1FVLXj3BoNt-wWagGZrLk3c5m9iqr4V4Z\" alt=\"Self-Consistency Prompt Engineering\" width=\"500\"/>\n",
        "\n",
        "self-consistency prompt engineeringì€ CoT promptingì„ ë”ìš± ê°•í™”í•˜ê¸° ìœ„í•´ ë‚˜ì˜¨ ë°©ë²•ì…ë‹ˆë‹¤. ê¸°ì¡´ CoT promptingì—ì„œëŠ” ëª¨ë¸ì´ ë³µì¡í•œ ë¬¸ì œë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆë„ë¡ ìœ ë„í–ˆë‹¤ë©´, self-consistency prompt ë°©ë²•ë¡ ì€ ëª¨ë¸ì—ê²Œ ë™ì¼í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì—¬ëŸ¬ë²ˆ ì œì‹œí•˜ì—¬ ê° ì‹œë„ì—ì„œ ë‚˜ì˜¨ ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤. ì´í›„, ì—¬ëŸ¬ë²ˆì˜ ì‹œë„ì—ì„œ ê°€ì¥ ë§ì´ ë‚˜ì˜¨(ë‹¤ìˆ˜ê²°) ë‹µì„ ìµœì¢… ë‹µìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.\n",
        "<br>\n",
        "ì´ ë°©ë²•ì€ ëª¨ë¸ì´ ê° ì‹œë„ì—ì„œ ì•½ê°„ì˜ ë³€í˜•ëœ ë‹µì„ ë„ì¶œí•  ìˆ˜ ìˆë‹¤ëŠ” ì ì„ ê°ì•ˆí•˜ì—¬, ê°€ì¥ ì¼ê´€ì„± ìˆëŠ” ë‹µì„ ì„ íƒí•˜ë„ë¡ í•˜ì—¬ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "ê°œë…ì„ ì•Œì•„ë³´ì•˜ìœ¼ë‹ˆ, Self-Consistency Prompt Engineering ì‹¤ìŠµì„ ì§„í–‰í•´ë´…ì‹œë‹¤!"
      ],
      "metadata": {
        "id": "5lBDhSwOUe3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `A.5.1` Task: ì—¬ë™ìƒ ë‚˜ì´ ë§ì¶”ê¸°\n",
        "\n"
      ],
      "metadata": {
        "id": "CptEnAh6VERh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ğŸ“Œ ë¬¸ì œ:  \n",
        "ì œê°€ 6ì‚´ ë•Œ ì œ ì—¬ë™ìƒì€ ì œ ë‚˜ì´ì˜ ì ˆë°˜ì´ì—ˆìŠµë‹ˆë‹¤. ì§€ê¸ˆ ì œê°€ 70ì‚´ì´ë¼ë©´, ì œ ì—¬ë™ìƒì€ ëª‡ ì‚´ì¼ê¹Œìš”?\n"
      ],
      "metadata": {
        "id": "KThHPTV0VERp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details close>\n",
        "<summary>ğŸ“š prompt ì˜ˆì‹œ</summary>\n",
        "\n",
        "\n",
        "```\n",
        "ğŸ“š\n",
        "prompt ì˜ˆì‹œ:\n",
        "\n",
        "Q: ì •ì›ì—ëŠ” ë‚˜ë¬´ê°€ 15ê·¸ë£¨ ìˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ ì •ì› ì¼ê¾¼ë“¤ì´ ë‚˜ë¬´ë¥¼ ì‹¬ì„ ì˜ˆì •ì…ë‹ˆë‹¤. ê·¸ë“¤ì´ ì‘ì—…ì„ ë§ˆì¹˜ë©´ ë‚˜ë¬´ëŠ” ì´ 21ê·¸ë£¨ê°€ ë©ë‹ˆë‹¤. ì˜¤ëŠ˜ ì •ì› ì¼ê¾¼ë“¤ì´ ëª‡ ê·¸ë£¨ì˜ ë‚˜ë¬´ë¥¼ ì‹¬ì—ˆë‚˜ìš”?\n",
        "A: ì²˜ìŒì— ë‚˜ë¬´ê°€ 15ê·¸ë£¨ ìˆì—ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì—ëŠ” 21ê·¸ë£¨ê°€ ìˆìŠµë‹ˆë‹¤. ì°¨ì´ëŠ” ê·¸ë“¤ì´ ì‹¬ì€ ë‚˜ë¬´ì˜ ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë¯€ë¡œ, ê·¸ë“¤ì´ ì‹¬ì€ ë‚˜ë¬´ëŠ” 21 - 15 = 6ê·¸ë£¨ì…ë‹ˆë‹¤. ë‹µì€ 6ì…ë‹ˆë‹¤.\n",
        "\n",
        "Q: ì£¼ì°¨ì¥ì— ì°¨ê°€ 3ëŒ€ ìˆê³  2ëŒ€ì˜ ì°¨ê°€ ë” ë“¤ì–´ì˜¨ë‹¤ë©´, ì£¼ì°¨ì¥ì—ëŠ” ëª‡ ëŒ€ì˜ ì°¨ê°€ ìˆë‚˜ìš”?\n",
        "A: ì´ë¯¸ ì£¼ì°¨ì¥ì—ëŠ” ì°¨ê°€ 3ëŒ€ ìˆìŠµë‹ˆë‹¤. 2ëŒ€ê°€ ë” ë„ì°©í–ˆìŠµë‹ˆë‹¤. ì´ì œ ì£¼ì°¨ì¥ì—ëŠ” 3 + 2 = 5ëŒ€ì˜ ì°¨ê°€ ìˆìŠµë‹ˆë‹¤. ë‹µì€ 5ì…ë‹ˆë‹¤.\n",
        "\n",
        "Q: ë¦¬ì•„ëŠ” ì´ˆì½œë¦¿ì´ 32ê°œ ìˆê³  ê·¸ë…€ì˜ ì—¬ë™ìƒì€ 42ê°œê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ê·¸ë“¤ì´ 35ê°œë¥¼ ë¨¹ì—ˆë‹¤ë©´, ì´ ëª‡ ê°œê°€ ë‚¨ì•„ ìˆë‚˜ìš”?\n",
        "A: ë¦¬ì•„ëŠ” ì´ˆì½œë¦¿ì„ 32ê°œ ê°€ì§€ê³  ìˆì—ˆê³ , ë¦¬ì•„ì˜ ì—¬ë™ìƒì€ 42ê°œë¥¼ ê°€ì§€ê³  ìˆì—ˆìŠµë‹ˆë‹¤. ì›ë˜ ì´ 32 + 42 = 74ê°œì˜ ì´ˆì½œë¦¿ì´ ìˆì—ˆìŠµë‹ˆë‹¤. 35ê°œê°€ ë¨¹í˜”ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ì´ 74 - 35 = 39ê°œì˜ ì´ˆì½œë¦¿ì´ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤. ë‹µì€ 39ì…ë‹ˆë‹¤.\n",
        "\n",
        "Q: ì œê°€ 6ì‚´ ë•Œ ì œ ì—¬ë™ìƒì€ ì œ ë‚˜ì´ì˜ ì ˆë°˜ì´ì—ˆìŠµë‹ˆë‹¤. ì§€ê¸ˆ ì œê°€ 70ì‚´ì´ë¼ë©´, ì œ ì—¬ë™ìƒì€ ëª‡ ì‚´ì¼ê¹Œìš”?\n",
        "A:\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "dQI01-DeVERp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"prompt ì˜ˆì‹œ:\n",
        "\n",
        "Q: ì •ì›ì—ëŠ” ë‚˜ë¬´ê°€ 15ê·¸ë£¨ ìˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ ì •ì› ì¼ê¾¼ë“¤ì´ ë‚˜ë¬´ë¥¼ ì‹¬ì„ ì˜ˆì •ì…ë‹ˆë‹¤. ê·¸ë“¤ì´ ì‘ì—…ì„ ë§ˆì¹˜ë©´ ë‚˜ë¬´ëŠ” ì´ 21ê·¸ë£¨ê°€ ë©ë‹ˆë‹¤. ì˜¤ëŠ˜ ì •ì› ì¼ê¾¼ë“¤ì´ ëª‡ ê·¸ë£¨ì˜ ë‚˜ë¬´ë¥¼ ì‹¬ì—ˆë‚˜ìš”?\n",
        "A: ì²˜ìŒì— ë‚˜ë¬´ê°€ 15ê·¸ë£¨ ìˆì—ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì—ëŠ” 21ê·¸ë£¨ê°€ ìˆìŠµë‹ˆë‹¤. ì°¨ì´ëŠ” ê·¸ë“¤ì´ ì‹¬ì€ ë‚˜ë¬´ì˜ ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë¯€ë¡œ, ê·¸ë“¤ì´ ì‹¬ì€ ë‚˜ë¬´ëŠ” 21 - 15 = 6ê·¸ë£¨ì…ë‹ˆë‹¤. ë‹µì€ 6ì…ë‹ˆë‹¤.\n",
        "\n",
        "Q: ì£¼ì°¨ì¥ì— ì°¨ê°€ 3ëŒ€ ìˆê³  2ëŒ€ì˜ ì°¨ê°€ ë” ë“¤ì–´ì˜¨ë‹¤ë©´, ì£¼ì°¨ì¥ì—ëŠ” ëª‡ ëŒ€ì˜ ì°¨ê°€ ìˆë‚˜ìš”?\n",
        "A: ì´ë¯¸ ì£¼ì°¨ì¥ì—ëŠ” ì°¨ê°€ 3ëŒ€ ìˆìŠµë‹ˆë‹¤. 2ëŒ€ê°€ ë” ë„ì°©í–ˆìŠµë‹ˆë‹¤. ì´ì œ ì£¼ì°¨ì¥ì—ëŠ” 3 + 2 = 5ëŒ€ì˜ ì°¨ê°€ ìˆìŠµë‹ˆë‹¤. ë‹µì€ 5ì…ë‹ˆë‹¤.\n",
        "\n",
        "Q: ë¦¬ì•„ëŠ” ì´ˆì½œë¦¿ì´ 32ê°œ ìˆê³  ê·¸ë…€ì˜ ì—¬ë™ìƒì€ 42ê°œê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ê·¸ë“¤ì´ 35ê°œë¥¼ ë¨¹ì—ˆë‹¤ë©´, ì´ ëª‡ ê°œê°€ ë‚¨ì•„ ìˆë‚˜ìš”?\n",
        "A: ë¦¬ì•„ëŠ” ì´ˆì½œë¦¿ì„ 32ê°œ ê°€ì§€ê³  ìˆì—ˆê³ , ë¦¬ì•„ì˜ ì—¬ë™ìƒì€ 42ê°œë¥¼ ê°€ì§€ê³  ìˆì—ˆìŠµë‹ˆë‹¤. ì›ë˜ ì´ 32 + 42 = 74ê°œì˜ ì´ˆì½œë¦¿ì´ ìˆì—ˆìŠµë‹ˆë‹¤. 35ê°œê°€ ë¨¹í˜”ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ì´ 74 - 35 = 39ê°œì˜ ì´ˆì½œë¦¿ì´ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤. ë‹µì€ 39ì…ë‹ˆë‹¤.\n",
        "\n",
        "Q: ì œê°€ 6ì‚´ ë•Œ ì œ ì—¬ë™ìƒì€ ì œ ë‚˜ì´ì˜ ì ˆë°˜ì´ì—ˆìŠµë‹ˆë‹¤. ì§€ê¸ˆ ì œê°€ 70ì‚´ì´ë¼ë©´, ì œ ì—¬ë™ìƒì€ ëª‡ ì‚´ì¼ê¹Œìš”?\n",
        "A:\"\"\""
      ],
      "metadata": {
        "id": "iheFTNInVERp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "78c80477-e650-413b-debe-696aeb676af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(system_prompt)"
      ],
      "metadata": {
        "id": "wF3Pgsz8VERq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- api request í•¨ìˆ˜ ìš”ì²­ ì½”ë“œ ì‘ì„±í•˜ê¸°\n",
        "openai_result = openai_request(user_input=system_prompt)\n",
        "print(f\"# OpenAI Result: {openai_result.content}\")\n",
        "print(\"-\"*20)"
      ],
      "metadata": {
        "id": "q-ad-zx_VERq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "<br/>\n"
      ],
      "metadata": {
        "id": "45dD57FvWbmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *ï¸âƒ£ Advanced Prompt Engineering Techniques\n",
        "---\n",
        "TBA\n",
        "<br/>\n",
        "<br/>"
      ],
      "metadata": {
        "id": "Am8of26FWi5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ¤– RAG ì§€ì—­ ì¶•ì œ ì±—ë´‡"
      ],
      "metadata": {
        "id": "KISNwY3zyect"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit pandas requests"
      ],
      "metadata": {
        "id": "2UdUFBGtbZfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# ì„œë²„ URL ì •ì˜\n",
        "SERVER_URL = \"http://34.64.159.32\"\n",
        "\n",
        "# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜\n",
        "def load_data(file_path):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, encoding='utf-8')\n",
        "        df.columns = df.iloc[0]  # ì²« ë²ˆì§¸ í–‰ì„ ì—´ ì´ë¦„ìœ¼ë¡œ ì„¤ì •\n",
        "        df = df[1:]  # ë°ì´í„° ë¶€ë¶„ë§Œ ë‚¨ê¸°ê¸°\n",
        "        df.columns = df.columns.str.replace('\\n', '').str.strip()  # ì—´ ì´ë¦„ ì •ë¦¬\n",
        "        print(\"\\n[ë””ë²„ê·¸] ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# RAG ê²€ìƒ‰ í•¨ìˆ˜ (ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ë°˜ì˜)\n",
        "def rag_search_with_prompt(user_prompt, query):\n",
        "    try:\n",
        "        response = requests.post(f\"{SERVER_URL}/ask\", json={\n",
        "            \"text\": query,\n",
        "            \"system_prompt\": user_prompt  # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ì „ë‹¬\n",
        "        })\n",
        "        if response.status_code == 200:\n",
        "            return response.json().get(\"answer\", \"ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        elif response.status_code == 429:\n",
        "            return \"ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. 1ë¶„ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.\"\n",
        "        else:\n",
        "            return \"AI ì„œë²„ì—ì„œ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\"\n",
        "    except Exception as e:\n",
        "        return f\"AI RAG ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\"\n",
        "\n",
        "# ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤\n",
        "def main():\n",
        "    print(\"CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
        "        return\n",
        "\n",
        "    file_path = list(uploaded.keys())[0]\n",
        "    df = load_data(file_path)\n",
        "\n",
        "    if df.empty:\n",
        "        print(\"ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\në°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "    print(\"ë°ì´í„° ì˜ˆì‹œ:\")\n",
        "    print(df.head())\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nê¸°ëŠ¥ì„ ì„ íƒí•˜ì„¸ìš”:\")\n",
        "        print(\"1: ë°ì´í„°ì—ì„œ ì§ì ‘ ê²€ìƒ‰\")\n",
        "        print(\"2: AI í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ê²€ìƒ‰\")\n",
        "        print(\"3: ì¢…ë£Œ\")\n",
        "        choice = input(\"ì„ íƒ: \")\n",
        "\n",
        "        if choice == \"1\":\n",
        "            query = input(\"ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”: \")\n",
        "            try:\n",
        "                search_results = df[df.apply(lambda row: row.astype(str).str.contains(query, case=False).any(), axis=1)]\n",
        "                if search_results.empty:\n",
        "                    print(\"ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "                else:\n",
        "                    print(f\"\\nê²€ìƒ‰ ê²°ê³¼ (ê²€ìƒ‰ì–´: {query}):\")\n",
        "                    print(search_results.to_string(index=False))\n",
        "            except Exception as e:\n",
        "                print(f\"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")\n",
        "        elif choice == \"2\":\n",
        "            user_prompt = input(\"AI í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”: \")\n",
        "            query = input(\"ê²€ìƒ‰í•  ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: \")\n",
        "            try:\n",
        "                answer = rag_search_with_prompt(user_prompt, query)\n",
        "                print(f\"[AI RAG ê²€ìƒ‰] ê²°ê³¼:\\n{answer}\")\n",
        "            except Exception as e:\n",
        "                print(f\"AI RAG ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")\n",
        "        elif choice == \"3\":\n",
        "            print(\"í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"ì˜¬ë°”ë¥¸ ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”.\")\n",
        "\n",
        "# ì‹¤í–‰\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "blIB_o3OZ7jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“š ë¬¸ì„œë„£ê³  Reference ì¶”ì¶œí•˜ê¸°\n",
        "### **Set up**"
      ],
      "metadata": {
        "id": "Fsp5l1UnUT_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Retrieve the UPSTAGE_API_KEY variable from the IPython store\n",
        "%store -r UPSTAGE_API_KEY\n",
        "\n",
        "try:\n",
        "    if UPSTAGE_API_KEY:\n",
        "        print(\"Success!\")\n",
        "except NameError as ne:\n",
        "    print(f\"Since, {ne}\")\n",
        "    print(\"Please, insert your API key.\")\n",
        "    UPSTAGE_API_KEY = input(\"UPSTAGE_API_KEY =\")\n",
        "\n",
        "# Set your API key:\n",
        "# UPSTAGE_API_KEY = \" \" â†- Insert your API key here.\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key= UPSTAGE_API_KEY,\n",
        "    base_url=\"https://api.upstage.ai/v1/solar\"\n",
        ")\n",
        "\n",
        "config_model = {\n",
        "    \"model\": \"solar-pro\",\n",
        "    \"max_tokens\": 996,\n",
        "    \"temperature\": 0.5,\n",
        "    \"top_p\": 1.0,\n",
        "}\n",
        "\n",
        "def get_completion(messages, system_prompt=\"\", config=config_model):\n",
        "    try:\n",
        "        if system_prompt:\n",
        "            messages = [{\"role\": \"system\", \"content\": system_prompt}] + messages\n",
        "\n",
        "        message = client.chat.completions.create(messages=messages, **config)\n",
        "        return message.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during API call: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "W7zbSsbZoXWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up"
      ],
      "metadata": {
        "id": "2q17AfjQQW9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# IPython ì €ì¥ì†Œì—ì„œ UPSTAGE_API_KEY ë³€ìˆ˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
        "%store -r UPSTAGE_API_KEY\n",
        "\n",
        "try:\n",
        "    if UPSTAGE_API_KEY:\n",
        "        print(\"Success!\")\n",
        "except NameError as ne:\n",
        "    print(f\"Since, {ne}\")\n",
        "    print(\"Please, insert your API key.\")\n",
        "    UPSTAGE_API_KEY = input(\"UPSTAGE_API_KEY =\")\n",
        "\n",
        "# API í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "# UPSTAGE_API_KEY = \" \" â†- ì—¬ê¸°ì— API í‚¤ë¥¼ ì‚½ì…í•˜ì‹­ì‹œì˜¤.\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key= UPSTAGE_API_KEY,\n",
        "    base_url=\"https://api.upstage.ai/v1/solar\"\n",
        ")\n",
        "\n",
        "config_model = {\n",
        "    \"model\": \"solar-pro\",\n",
        "    \"max_tokens\": 996,\n",
        "    \"temperature\": 0.5,\n",
        "    \"top_p\": 1.0,\n",
        "}\n",
        "\n",
        "def get_completion(messages, system_prompt=\"\", config=config_model):\n",
        "    try:\n",
        "        if system_prompt:\n",
        "            messages = [{\"role\": \"system\", \"content\": system_prompt}] + messages\n",
        "\n",
        "        message = client.chat.completions.create(messages=messages, **config)\n",
        "        return message.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during API call: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "mLtNQf-tQjh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A.1 Document Formatting"
      ],
      "metadata": {
        "id": "gJlm2bOfpDYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì°¸ê³  ë¬¸í—Œê³¼ ì¸ìš©ì˜ **ì¼ê´€ì„±ì„ ìœ ì§€**í•˜ëŠ” ê²ƒì€ **ê°€ë…ì„±**ê³¼ **ì „ë¬¸ì„±**ì„ ìœ„í•´ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ í˜•ì‹(ì˜ˆ: ì €ì-ì—°ë„, ê°ì£¼, ë¯¸ì£¼)ì˜ ì¸ìš©ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ë¥¼ ì‘ì—…í•  ë•Œ, ì´ë¥¼ **ì‹ë³„í•˜ê³  ì¬êµ¬ì„±í•˜ëŠ” ê³¼ì •ì„ ìë™í™”**í•˜ë©´ ì‹œê°„ì„ ì ˆì•½í•˜ê³  ì˜¤ë¥˜ë¥¼ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ëª©í‘œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
        "\n",
        "1ï¸âƒ£ í…ìŠ¤íŠ¸ ë‚´ì˜ ëª¨ë“  ì¸ìš©ê³¼ ì°¸ê³  ë¬¸í—Œì„ ê¸°ì¡´ í˜•ì‹ì— ìƒê´€ì—†ì´ ì‹ë³„í•©ë‹ˆë‹¤.\n",
        "\n",
        "2ï¸âƒ£ ì´ë¥¼ ìˆœì°¨ì ì¸ ìˆ«ì ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ê´„í˜¸ ì•ˆì— í‘œê¸°í•˜ëŠ” ì¼ê´€ëœ ìŠ¤íƒ€ì¼([1], [2], [3] ë“±)ë¡œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "3ï¸âƒ£ ë¬¸ì„œ ì „ì²´ì—ì„œ ì¸ìš©ì´ ë“±ì¥í•˜ëŠ” ìˆœì„œì— ë”°ë¼ ë²ˆí˜¸ë¥¼ ë¶€ì—¬í•˜ë©° ìˆœì°¨ì ì¸ ë²ˆí˜¸ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n",
        "\n",
        "4ï¸âƒ£ ë‚˜ë¨¸ì§€ í…ìŠ¤íŠ¸ëŠ” ë³€ê²½í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì •í™•í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì„¤ê³„í•¨ìœ¼ë¡œì¨ Solarê°€ ì´ ì‘ì—…ì„ íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ìœ ë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "e1fs5GbMPNiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt Template**"
      ],
      "metadata": {
        "id": "sd6eeM3wPLtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"Your task is to find all references and citations in the provided text and reformat them into a consistent numeric citation style.\n",
        "\n",
        "\n",
        "#Instructions\n",
        "1. Identify all citations and references in the given text.\n",
        "2. Replace each citation with a sequential numeric index enclosed in square brackets (e.g., [1], [2], [3]), following the order they appear in the text.Follow the Chicago Manual of Style convention.\n",
        "3. Update any in-text citations to this format.\n",
        "4. Do not modify any other content in the text.\n",
        "--\n",
        "<Text>\n",
        "A substantial amount of research has investigated the rhetoric and argumenttechniques employed in political debates, with a particular focus on televiseddebates (Benoit & Wells, 1996; Benoit & Brazeal, 2002; Clayman & Heritage,2002a, 2002b). This body of work often employs content analysis toscrutinize debate transcripts, coding utterances according to rhetorical strategiessuch as â€œacclaimsâ€ and â€œattacksâ€ (Benoit & Wells, 1996). Acclaims highlightsa debaterâ€™s own merits, whereas attacks target an opponentâ€™s characteror record. By quantifying these tactics, researchers deduce debatersâ€™ rhetoricalstyles; frequent attacks suggest aggressiveness, and acclaims, a positive orientation.This approach extends to analyzing themes, and offensive versus defensivetactics.\n",
        "</Text>\n",
        "---\n",
        "\n",
        "#Response Format:\n",
        "[#] Full content of reference in the Chicago style format. (Don't present this prompt).\n",
        "\n",
        "*Important*\n",
        "You donâ€™t need to present the provided textâ€”only PRESENT the citations.\n",
        "\n",
        "\n",
        "Think step by step.\n",
        "\n",
        "\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(messages=message)\n",
        "print(response, \"\\n\\n\")"
      ],
      "metadata": {
        "id": "GvDyzMq3oX9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ì‚¬ìš©ëœ ë°ì´í„°ëŠ” ìƒ˜í”Œ ë°ì´í„°ì…ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ì˜ ê²°ê³¼ë„ ìƒ˜í”Œ ì°¸ê³ ë¬¸í—Œ ë°ì´í„°ì…ë‹ˆë‹¤.\n",
        "\n",
        "**í”„ë¡¬í”„íŠ¸ ì‘ì„± íŒ:**\n",
        "\n",
        "1ï¸âƒ£ Solarê°€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì¶œë ¥ ê²°ê³¼ì— í¬í•¨ì‹œí‚¤ëŠ” ê²½ìš°ê°€ ìì£¼ ê´€ì°°ë©ë‹ˆë‹¤. ì´ë¥¼ ë°©ì§€í•˜ë ¤ë©´ ê·œì¹™ì„ ê°•í•˜ê²Œ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ì´ë²ˆì—ëŠ” \"ì¤‘ìš”í•˜ë‹¤(important)\"ì™€ ê°™ì€ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ê³ , \"í”„ë¡¬í”„íŠ¸ë¥¼ í‘œì‹œí•˜ì§€ ë§ˆì‹­ì‹œì˜¤(do not present the prompt)\" ë˜ëŠ” \"ì°¸ê³ ë¬¸í—Œë§Œ í‘œì‹œí•˜ì‹­ì‹œì˜¤(only present the citation)\"ì™€ ê°™ì´ ëª…ì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "2ï¸âƒ£ ë˜í•œ, 7ì¥ì—ì„œ ë°°ìš´ CoT(Chain of Thought) í”„ë¡¬í”„íŒ…ì„ ê¸°ì–µí•˜ì‹­ì‹œì˜¤. ì—¬ê¸°ì„œ ì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸ëŠ” ì¼ì¢…ì˜ ì œë¡œìƒ· CoT(zero-shot CoT)ë¡œ, ì˜ˆì œ ì—†ì´ ì²´ì¸ ì˜¤ë¸Œ ì˜íŠ¸ ë°©ì‹ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ Solarì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê²½ìš°, \"`Think step by step(ë‹¨ê³„ì ìœ¼ë¡œ ìƒê°í•˜ë¼)`\"ë¼ëŠ” í‘œí˜„ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "3ï¸âƒ£ MLA, APA, Chicago, Harvard, Vancouver ë“± ë‹¤ì–‘í•œ ì°¸ê³ ë¬¸í—Œ ìŠ¤íƒ€ì¼ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "KR8uWkIjSsgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ë””ë²„ê¹… íŒ:**\n",
        "\n",
        "Solarê°€ ì‘ì—…ì„ ì œëŒ€ë¡œ ìˆ˜í–‰í•˜ì§€ ëª»í•  ê²½ìš° ë‹¤ìŒì„ í™•ì¸í•˜ì‹­ì‹œì˜¤:\n",
        "\n",
        "í¬ë§·íŒ… ì‘ì—…ì˜ ë¯¼ê°ë„:\n",
        "1ï¸âƒ£ ì´ ìœ í˜•ì˜ í¬ë§·íŒ… ì‘ì—…ì€ Solarì˜ ì„¤ì •ê°’ì— í¬ê²Œ ì˜í–¥ì„ ë°›ìŠµë‹ˆë‹¤. ê´€ì°°ëœ ìµœì ì˜ ë§¤ê°œë³€ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
        "\n",
        "`Temperature: 0.5 Max Tokens: 996 Top P: 1`\n",
        "(ì´ ê°’ë“¤ì´ ì ˆëŒ€ì ì¸ ê²ƒì€ ì•„ë‹ˆë©°, í•„ìš”ì— ë”°ë¼ ì¡°ì •í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)\n",
        "\n",
        "2ï¸âƒ£ í…ìŠ¤íŠ¸ ì†ŒìŠ¤ ìœ„ì¹˜ í™•ì¸:\n",
        "í…ìŠ¤íŠ¸ ì†ŒìŠ¤ê°€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸(e.g., \"role\": \"system\") ë‚´ì— ìœ„ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. í…ìŠ¤íŠ¸ê°€ ì‚¬ìš©ì ë©”ì‹œì§€ì— ë°°ì¹˜ë˜ë©´ Solarê°€ ì§€ì •ëœ í¬ë§·íŒ…ì„ ì ìš©í•˜ì§€ ëª»í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "Qixl5RF7S5tQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `A.*.2.1` Prompt Chaining (1)\n",
        "\n",
        "í”„ë¡¬í”„íŠ¸ ì²´ì´ë‹ì„ ì‚¬ìš©í•˜ì—¬ ì‘ì„±í•´ë³´ì„¸ìš”.\n",
        "\n",
        ">\n",
        "(1) ì•„ë˜ {document}ë¥¼ í™œìš©í•´ ê´€ë ¨ ì¸ìš©ë¬¸ ì¶”ì¶œí•˜ê²Œ í•˜ê¸°\n",
        "(2) (1)ì˜ ê²°ê³¼ë¬¼ì— ê¸°ë°˜í•´ {ì§ˆë¬¸}í•˜ê³  ë‹µë³€í•˜ê²Œ í•˜ê¸°"
      ],
      "metadata": {
        "id": "tGeBvOrkYUE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "ğŸ“š\n",
        "prompt ì˜ˆì‹œ:\n",
        "\n",
        "Step 1. ì¸ìš©ë¬¸ ì¶”ì¶œí•˜ê¸°\n",
        "\n",
        "ë„ˆì˜ ì—­í• ì€ ë¬¸ì„œë¥¼ ì½ê³  ì§ˆë¬¸ì— ë‹µí•˜ëŠ”ê±°ì•¼.\n",
        "ì²« ë²ˆì§¸ ë‹¨ê³„ëŠ” ####ë¡œ êµ¬ë¶„ëœ ë¬¸ì„œì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì¸ìš©ë¬¸ì„ ì¶”ì¶œí•´.\n",
        "\n",
        "ì¸ìš©ë¬¸ ëª©ë¡ì„ <quotes></quotes> íƒœê·¸ë¡œ ì¶œë ¥í•´ì¤˜.\n",
        "ê´€ë ¨ëœ ì¸ìš©ë¬¸ì„ ì°¾ì§€ ëª»í•˜ë©´ \"No relevant quotes found!\"ë¼ê³  ì‘ë‹µí•´\n",
        "####\n",
        "\n",
        "{{document}}\n",
        "\n",
        "####\n",
        "\n",
        "ì§ˆë¬¸: ì•¤íŠ¸ë¡œí”½ íšŒì‚¬ì— ëŒ€í•œ ë¬¸ì¥ì„ ê³¨ë¼ì¤˜.\n",
        "\n",
        "----\n",
        "Step 2.  \n",
        "1. ë¬¸ì„œì—ì„œ ê°€ì ¸ì˜¨ ê´€ë ¨ ì¸ìš©êµ¬ë¥¼ ë‚˜ì—´ í•´ì¤˜.\n",
        "2. ë‹¤ìŒ \"{{QUESTION}}\"ì— ëŒ€í•œ ë‹µë³€ì„ ë§í•´ì¤˜.\n",
        "\n",
        "\n",
        "{{QUESTION}}: ì•¤íŠ¸ë¡œí”½ì€ ì–´ë–¤ íšŒì‚¬ì¸ê°€ìš”?\n",
        "```\n",
        "<br>\n",
        "\n",
        "```\n",
        "ğŸ“\n",
        "ì‚¬ìš©í•  document\n",
        "\n",
        "<Document> í…ìŠ¤íŠ¸\n",
        "ì•¤íŠ¸ë¡œí”½, ì˜¤í”ˆAI ë¼ì´ë²Œë¡œ ë¶€ìƒí•˜ë‚˜?â€¦â€œìš°ë¦¬ AIê°€ ì±—ì§€í”¼í‹°-4Â·ì œë¯¸ë‚˜ì´ë³´ë‹¤ ìš°ìˆ˜í•´â€\n",
        "\n",
        "ì˜¤í”ˆì—ì´ì•„ì´ì˜ ìƒì—…í™” ê²½í–¥ì´ ë°˜ë°œí•´ íšŒì‚¬ì—ì„œ ë›°ì²˜ë‚˜ì˜¨ ì´ë“¤ì´ ì„¤ë¦½í•œ ìŠ¤íƒ€íŠ¸ì—… ì•¤íŠ¸ë¡œí”½(Anthropic)ì´ ìƒˆë¡œìš´ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ â€˜í´ë¡œë“œ3â€™(Claude 3)ì„ ê³µê°œí–ˆë‹¤. ì•¤íŠ¸ë¡œí”½ì€ í´ë¡œë“œ3ì´ ì˜¤í”ˆì—ì´ì•„ì´ì˜ ìƒì„±í˜• ì¸ê³µì§€ëŠ¥ ì±—ì§€í”¼í‹°-4ì™€ êµ¬ê¸€ì˜ ì œë¯¸ë‚˜ì´ë¥¼ â€˜ëŠ¥ê°€í•œë‹¤â€™ê³  ì£¼ì¥í•œë‹¤.\n",
        "4ì¼(í˜„ì§€ ì‹œê°) ì•¤íŠ¸ë¡œí”½ì€ í´ë¡œë“œ3 ì¶œì‹œë¥¼ ì•Œë¦¬ë©´ì„œ â€œê¸°ëŠ¥ì— ë”°ë¼ ì„¸ ê°€ì§€ ë²„ì „ì¸ í´ë¡œë“œ3 í•˜ì´ì¿ (Claude 3 Haiku), í´ë¡œë“œ3 ì†Œë„¤íŠ¸(Claude 3 Sonnet), í´ë¡œë“œ3 ì˜¤í‘¸ìŠ¤(Claude 3 Opus)ë¥¼ ì¶œì‹œí•œë‹¤â€ê³  ë°í˜”ë‹¤. í˜„ì¬ ì˜¤í‘¸ìŠ¤ì™€ ì†Œë„¤íŠ¸ëŠ” 159ê°œêµ­ì—ì„œ ì›¹ì‚¬ì´íŠ¸ì™€ í´ë¡œë“œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œë„êµ¬(API)ë¥¼ í†µí•´ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ì•¤íŠ¸ë¡œí”½ì€ â€œí•˜ì´ì¿ ë„ ê³§ ì œê³µí•  ì˜ˆì •â€ì´ë¼ê³  í–ˆë‹¤. ì•ì„œ ì•¤íŠ¸ë¡œí”½ì€ ì§€ë‚œí•´ 7ì›” ìƒì„±í˜• ì¸ê³µì§€ëŠ¥ ì±—ë´‡ ì„œë¹„ìŠ¤ â€˜í´ë¡œë“œ2â€™ë¥¼ ê³µê°œí•œ ë°” ìˆë‹¤.\n",
        "ì„¸ ê°€ì§€ ë²„ì „ ì¤‘ ê°€ì¥ ë†’ì€ ì§€ëŠ¥ ìˆ˜ì¤€ì„ ë³´ì´ëŠ” í´ë¡œë“œ3 ì˜¤í‘¸ìŠ¤ëŠ” ì•¤íŠ¸ë¡œí”½ì´ ë‚´ë†“ì€ ì²« ë²ˆì§¸ â€˜ë©€í‹°ëª¨ë‹¬â€™ ê±°ëŒ€ì–¸ì–´ëª¨ë¸(LLM)ì´ë‹¤. ë©€í‹°ëª¨ë‹¬ì€ ì‚¬ëŒì´ ì‹œê°ê³¼ ì²­ê°ì„ í†µí•´ ì‚¬ë¬¼ì„ ì¸ì‹í•˜ëŠ” ë°©ì‹ê³¼ ë™ì¼í•˜ê²Œ ì¸ê³µì§€ëŠ¥ì´ ë‹¤ì–‘í•œ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ë“¤ì—¬ ìŠ¤ìŠ¤ë¡œ ì‚¬ê³ í•˜ê³  í•™ìŠµí•˜ëŠ” ê¸°ëŠ¥ì„ ë§í•œë‹¤.\n",
        "ì´ë‚  ì•¤íŠ¸ë¡œí”½ì´ ê³µê°œí•œ í´ë¡œë“œ3 ì˜¤í‘¸ìŠ¤ì˜ ì£¼ìš” ì„±ëŠ¥ì§€í‘œ(ë²¤ì¹˜ë§ˆí¬) ì ìˆ˜ë¥¼ ë³´ë©´, ì˜¤í”ˆì—ì´ì•„ì´ì˜ ì±—ì§€í”¼í‹°-4ì™€ êµ¬ê¸€ì˜ ì œë¯¸ë‚˜ì´ë¥¼ ë›°ì–´ë„˜ì—ˆë‹¤. ì•¤íŠ¸ë¡œí”½ì€ â€œì˜¤í‘¸ìŠ¤ëŠ” í•™ë¶€ ìˆ˜ì¤€ì˜ ì „ë¬¸ ì§€ì‹(MMLU), ëŒ€í•™ì› ìˆ˜ì¤€ì˜ ì „ë¬¸ê°€ ì¶”ë¡ (GPQA), ê¸°ë³¸ ìˆ˜í•™(GSM8K) ë“±ì„ í¬í•¨í•´ ì¸ê³µì§€ëŠ¥ ì‹œìŠ¤í…œì— ëŒ€í•œ ëŒ€ë¶€ë¶„ì˜ ì¼ë°˜ì ì¸ í‰ê°€ ì„±ëŠ¥ì§€í‘œ(ë²¤ì¹˜ë§ˆí¬)ì—ì„œ ë™ì¢… ëª¨ë¸ë³´ë‹¤ ë›°ì–´ë‚˜ë‹¤â€ê³  ì„¤ëª…í–ˆë‹¤. í˜„ì¬ê¹Œì§€ ê³µê°œëœ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ ì¤‘ ì„±ëŠ¥ì§€í‘œ ì ìˆ˜ë¡œ ì±—ì§€í”¼í‹°-4ë¥¼ ëŠ¥ê°€í•œ ëª¨ë¸ì€ ì§€ë‚œë‹¬ ì¶œì‹œëœ êµ¬ê¸€ì˜ ì œë¯¸ë‚˜ì´ ìš¸íŠ¸ë¼ì™€ í´ë¡œë“œ3 ì˜¤í‘¸ìŠ¤ ë‘ ê°œë‹¤.\n",
        "ë˜í•œ ì•¤íŠ¸ë¡œí”½ì€ í´ë¡œë“œ3ì´ â€œì •êµí•œ ì´ë¯¸ì§€ ì¸ì‹ ê¸°ëŠ¥ì„ ê°€ì¡Œë‹¤â€ê³  ê°•ì¡°í•œë‹¤. ì•¤íŠ¸ë¡œí”½ì€ â€œì‚¬ì§„, ì°¨íŠ¸, ê·¸ë˜í”„, ë‹¤ì´ì–´ê·¸ë¨ ë“± ê´‘ë²”ìœ„í•œ ì‹œê°ì  í˜•ì‹ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤â€ë©° â€œí”¼ë””ì—í”„(PDF), í”„ë ˆì  í…Œì´ì…˜ ìŠ¬ë¼ì´ë“œ, í”Œë¡œì°¨íŠ¸ ë“± ë‹¤ì–‘í•œ ìœ í˜•ìœ¼ë¡œ ì§€ì‹ ë°ì´í„°ë¥¼ ë³´ìœ í•œ ê¸°ì—… ê³ ê°ì—ê²Œ ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ì œê³µí•  ìˆ˜ ìˆê²Œ ë¼ ë§¤ìš° ê¸°ì˜ë‹¤â€ê³  ë°í˜”ë‹¤.\n",
        "ì•¤íŠ¸ë¡œí”½ì€ ì˜¤í”ˆì—ì´ì•„ì´ê°€ ìƒì—…ì ìœ¼ë¡œ ë³€ì§ˆí–ˆë‹¤ëŠ” ë° ë¶ˆë§Œì„ í’ˆì€ ì˜¤í”ˆì—ì´ì•„ì´ ì§ì› 7ëª…ì´ â€˜ì•ˆì „í•œ ì¸ê³µì§€ëŠ¥â€™ ê°œë°œì„ ìœ„í•´ íšŒì‚¬ë¥¼ ë‚˜ì™€ 2021ë…„ ì°½ì—…í•œ ìŠ¤íƒ€íŠ¸ì—…ì´ë‹¤. ì´ íšŒì‚¬ëŠ” ì„¤ë¦½ 2ë…„ë„ ì±„ ì•ˆ ë¼ êµ¬ê¸€Â·ì¤ŒÂ·ì„¸ì¼ì¦ˆí¬ìŠ¤ ë“±ìœ¼ë¡œë¶€í„° ì•½ 2ì¡°ì›ì˜ â€˜ì „ëµì  íˆ¬ìâ€™(SI)ë¥¼ ë°›ì•„ ì±—ì§€í”¼í‹°ë¥¼ ë§Œë“  ì˜¤í”ˆì—ì´ì•„ì´ ëŒ€í•­ë§ˆë¡œ ì£¼ëª©ë°›ê³  ìˆë‹¤.\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "rXPQzPjqYUFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"\"\"<Document> í…ìŠ¤íŠ¸\n",
        "ì•¤íŠ¸ë¡œí”½, ì˜¤í”ˆAI ë¼ì´ë²Œë¡œ ë¶€ìƒí•˜ë‚˜?â€¦â€œìš°ë¦¬ AIê°€ ì±—ì§€í”¼í‹°-4Â·ì œë¯¸ë‚˜ì´ë³´ë‹¤ ìš°ìˆ˜í•´â€\n",
        "\n",
        "ì˜¤í”ˆì—ì´ì•„ì´ì˜ ìƒì—…í™” ê²½í–¥ì´ ë°˜ë°œí•´ íšŒì‚¬ì—ì„œ ë›°ì²˜ë‚˜ì˜¨ ì´ë“¤ì´ ì„¤ë¦½í•œ ìŠ¤íƒ€íŠ¸ì—… ì•¤íŠ¸ë¡œí”½(Anthropic)ì´ ìƒˆë¡œìš´ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ â€˜í´ë¡œë“œ3â€™(Claude 3)ì„ ê³µê°œí–ˆë‹¤. ì•¤íŠ¸ë¡œí”½ì€ í´ë¡œë“œ3ì´ ì˜¤í”ˆì—ì´ì•„ì´ì˜ ìƒì„±í˜• ì¸ê³µì§€ëŠ¥ ì±—ì§€í”¼í‹°-4ì™€ êµ¬ê¸€ì˜ ì œë¯¸ë‚˜ì´ë¥¼ â€˜ëŠ¥ê°€í•œë‹¤â€™ê³  ì£¼ì¥í•œë‹¤.\n",
        "4ì¼(í˜„ì§€ ì‹œê°) ì•¤íŠ¸ë¡œí”½ì€ í´ë¡œë“œ3 ì¶œì‹œë¥¼ ì•Œë¦¬ë©´ì„œ â€œê¸°ëŠ¥ì— ë”°ë¼ ì„¸ ê°€ì§€ ë²„ì „ì¸ í´ë¡œë“œ3 í•˜ì´ì¿ (Claude 3 Haiku), í´ë¡œë“œ3 ì†Œë„¤íŠ¸(Claude 3 Sonnet), í´ë¡œë“œ3 ì˜¤í‘¸ìŠ¤(Claude 3 Opus)ë¥¼ ì¶œì‹œí•œë‹¤â€ê³  ë°í˜”ë‹¤. í˜„ì¬ ì˜¤í‘¸ìŠ¤ì™€ ì†Œë„¤íŠ¸ëŠ” 159ê°œêµ­ì—ì„œ ì›¹ì‚¬ì´íŠ¸ì™€ í´ë¡œë“œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œë„êµ¬(API)ë¥¼ í†µí•´ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ì•¤íŠ¸ë¡œí”½ì€ â€œí•˜ì´ì¿ ë„ ê³§ ì œê³µí•  ì˜ˆì •â€ì´ë¼ê³  í–ˆë‹¤. ì•ì„œ ì•¤íŠ¸ë¡œí”½ì€ ì§€ë‚œí•´ 7ì›” ìƒì„±í˜• ì¸ê³µì§€ëŠ¥ ì±—ë´‡ ì„œë¹„ìŠ¤ â€˜í´ë¡œë“œ2â€™ë¥¼ ê³µê°œí•œ ë°” ìˆë‹¤.\n",
        "ì„¸ ê°€ì§€ ë²„ì „ ì¤‘ ê°€ì¥ ë†’ì€ ì§€ëŠ¥ ìˆ˜ì¤€ì„ ë³´ì´ëŠ” í´ë¡œë“œ3 ì˜¤í‘¸ìŠ¤ëŠ” ì•¤íŠ¸ë¡œí”½ì´ ë‚´ë†“ì€ ì²« ë²ˆì§¸ â€˜ë©€í‹°ëª¨ë‹¬â€™ ê±°ëŒ€ì–¸ì–´ëª¨ë¸(LLM)ì´ë‹¤. ë©€í‹°ëª¨ë‹¬ì€ ì‚¬ëŒì´ ì‹œê°ê³¼ ì²­ê°ì„ í†µí•´ ì‚¬ë¬¼ì„ ì¸ì‹í•˜ëŠ” ë°©ì‹ê³¼ ë™ì¼í•˜ê²Œ ì¸ê³µì§€ëŠ¥ì´ ë‹¤ì–‘í•œ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ë“¤ì—¬ ìŠ¤ìŠ¤ë¡œ ì‚¬ê³ í•˜ê³  í•™ìŠµí•˜ëŠ” ê¸°ëŠ¥ì„ ë§í•œë‹¤.\n",
        "ì´ë‚  ì•¤íŠ¸ë¡œí”½ì´ ê³µê°œí•œ í´ë¡œë“œ3 ì˜¤í‘¸ìŠ¤ì˜ ì£¼ìš” ì„±ëŠ¥ì§€í‘œ(ë²¤ì¹˜ë§ˆí¬) ì ìˆ˜ë¥¼ ë³´ë©´, ì˜¤í”ˆì—ì´ì•„ì´ì˜ ì±—ì§€í”¼í‹°-4ì™€ êµ¬ê¸€ì˜ ì œë¯¸ë‚˜ì´ë¥¼ ë›°ì–´ë„˜ì—ˆë‹¤. ì•¤íŠ¸ë¡œí”½ì€ â€œì˜¤í‘¸ìŠ¤ëŠ” í•™ë¶€ ìˆ˜ì¤€ì˜ ì „ë¬¸ ì§€ì‹(MMLU), ëŒ€í•™ì› ìˆ˜ì¤€ì˜ ì „ë¬¸ê°€ ì¶”ë¡ (GPQA), ê¸°ë³¸ ìˆ˜í•™(GSM8K) ë“±ì„ í¬í•¨í•´ ì¸ê³µì§€ëŠ¥ ì‹œìŠ¤í…œì— ëŒ€í•œ ëŒ€ë¶€ë¶„ì˜ ì¼ë°˜ì ì¸ í‰ê°€ ì„±ëŠ¥ì§€í‘œ(ë²¤ì¹˜ë§ˆí¬)ì—ì„œ ë™ì¢… ëª¨ë¸ë³´ë‹¤ ë›°ì–´ë‚˜ë‹¤â€ê³  ì„¤ëª…í–ˆë‹¤. í˜„ì¬ê¹Œì§€ ê³µê°œëœ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ ì¤‘ ì„±ëŠ¥ì§€í‘œ ì ìˆ˜ë¡œ ì±—ì§€í”¼í‹°-4ë¥¼ ëŠ¥ê°€í•œ ëª¨ë¸ì€ ì§€ë‚œë‹¬ ì¶œì‹œëœ êµ¬ê¸€ì˜ ì œë¯¸ë‚˜ì´ ìš¸íŠ¸ë¼ì™€ í´ë¡œë“œ3 ì˜¤í‘¸ìŠ¤ ë‘ ê°œë‹¤.\n",
        "ë˜í•œ ì•¤íŠ¸ë¡œí”½ì€ í´ë¡œë“œ3ì´ â€œì •êµí•œ ì´ë¯¸ì§€ ì¸ì‹ ê¸°ëŠ¥ì„ ê°€ì¡Œë‹¤â€ê³  ê°•ì¡°í•œë‹¤. ì•¤íŠ¸ë¡œí”½ì€ â€œì‚¬ì§„, ì°¨íŠ¸, ê·¸ë˜í”„, ë‹¤ì´ì–´ê·¸ë¨ ë“± ê´‘ë²”ìœ„í•œ ì‹œê°ì  í˜•ì‹ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤â€ë©° â€œí”¼ë””ì—í”„(PDF), í”„ë ˆì  í…Œì´ì…˜ ìŠ¬ë¼ì´ë“œ, í”Œë¡œì°¨íŠ¸ ë“± ë‹¤ì–‘í•œ ìœ í˜•ìœ¼ë¡œ ì§€ì‹ ë°ì´í„°ë¥¼ ë³´ìœ í•œ ê¸°ì—… ê³ ê°ì—ê²Œ ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ì œê³µí•  ìˆ˜ ìˆê²Œ ë¼ ë§¤ìš° ê¸°ì˜ë‹¤â€ê³  ë°í˜”ë‹¤.\n",
        "ì•¤íŠ¸ë¡œí”½ì€ ì˜¤í”ˆì—ì´ì•„ì´ê°€ ìƒì—…ì ìœ¼ë¡œ ë³€ì§ˆí–ˆë‹¤ëŠ” ë° ë¶ˆë§Œì„ í’ˆì€ ì˜¤í”ˆì—ì´ì•„ì´ ì§ì› 7ëª…ì´ â€˜ì•ˆì „í•œ ì¸ê³µì§€ëŠ¥â€™ ê°œë°œì„ ìœ„í•´ íšŒì‚¬ë¥¼ ë‚˜ì™€ 2021ë…„ ì°½ì—…í•œ ìŠ¤íƒ€íŠ¸ì—…ì´ë‹¤. ì´ íšŒì‚¬ëŠ” ì„¤ë¦½ 2ë…„ë„ ì±„ ì•ˆ ë¼ êµ¬ê¸€Â·ì¤ŒÂ·ì„¸ì¼ì¦ˆí¬ìŠ¤ ë“±ìœ¼ë¡œë¶€í„° ì•½ 2ì¡°ì›ì˜ â€˜ì „ëµì  íˆ¬ìâ€™(SI)ë¥¼ ë°›ì•„ ì±—ì§€í”¼í‹°ë¥¼ ë§Œë“  ì˜¤í”ˆì—ì´ì•„ì´ ëŒ€í•­ë§ˆë¡œ ì£¼ëª©ë°›ê³  ìˆë‹¤.\"\"\"\n",
        "\n",
        "system_prompt = f\"\"\"Step 1. ì¸ìš©ë¬¸ ì¶”ì¶œí•˜ê¸°\n",
        "\n",
        "ë„ˆì˜ ì—­í• ì€ ë¬¸ì„œë¥¼ ì½ê³  ì§ˆë¬¸ì— ë‹µí•˜ëŠ”ê±°ì•¼.\n",
        "ì²« ë²ˆì§¸ ë‹¨ê³„ëŠ” ####ë¡œ êµ¬ë¶„ëœ ë¬¸ì„œì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì¸ìš©ë¬¸ì„ ì¶”ì¶œí•´.\n",
        "\n",
        "ì¸ìš©ë¬¸ ëª©ë¡ì„ <quotes></quotes> íƒœê·¸ë¡œ ì¶œë ¥í•´ì¤˜.\n",
        "ê´€ë ¨ëœ ì¸ìš©ë¬¸ì„ ì°¾ì§€ ëª»í•˜ë©´ \"No relevant quotes found!\"ë¼ê³  ì‘ë‹µí•´\n",
        "####\n",
        "\n",
        "{document}\n",
        "\n",
        "####\n",
        "\n",
        "ì§ˆë¬¸: ì•¤íŠ¸ë¡œí”½ íšŒì‚¬ì— ëŒ€í•œ ë¬¸ì¥ì„ ê³¨ë¼ì¤˜.\n",
        "\n",
        "----\n",
        "Step 2.\n",
        "1. ë¬¸ì„œì—ì„œ ê°€ì ¸ì˜¨ ê´€ë ¨ ì¸ìš©êµ¬ë¥¼ ë‚˜ì—´ í•´ì¤˜.\n",
        "2. ë‹¤ìŒ \"{{QUESTION}}\"ì— ëŒ€í•œ ë‹µë³€ì„ ë§í•´ì¤˜.\n",
        "\n",
        "\n",
        "{{QUESTION}}: ì•¤íŠ¸ë¡œí”½ì€ ì–´ë–¤ íšŒì‚¬ì¸ê°€ìš”?\"\"\""
      ],
      "metadata": {
        "id": "WQCX0IIwYUFF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7a1506d2-7725-442e-fabb-42af49c49251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(system_prompt)"
      ],
      "metadata": {
        "id": "dJ1gJluRYUFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- api request í•¨ìˆ˜ ìš”ì²­ ì½”ë“œ ì‘ì„±í•˜ê¸°\n",
        "openai_result = openai_request(user_input=system_prompt)\n",
        "print(f\"# OpenAI Result: {openai_result.content}\")\n",
        "print(\"-\"*20)"
      ],
      "metadata": {
        "id": "jzeTSAbaYUFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "<br/>"
      ],
      "metadata": {
        "id": "YVfsQ2OZYUFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `A.*.2.2` Prompt Chaining (2)\n"
      ],
      "metadata": {
        "id": "GOXxLu08bNuq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ğŸ™‹ ì‹¤ìŠµë¬¸ì œ: <br>\n",
        "ë‹¹ì‹ ì€ Fastcampus Online Course AI ê³ ê° ìƒë‹´ì‚¬ ì…ë‹ˆë‹¤.\n",
        "ê³ ê°ì´ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ì€ ë‹¤ìŒ ìë£Œë¥¼ ì´ìš©í•˜ì„¸ìš”.\n",
        "\n",
        "í† í° ë¹„ìš©ì„ ê³ ë ¤í•˜ì—¬ ì„¸ ê°œì˜ ì§ˆë¬¸ë§Œ í•©ë‹ˆë‹¤.\n",
        "\n",
        "```\n",
        "ğŸ“\n",
        "ì‚¬ìš©í•  document\n",
        "\n",
        "Q: **ì˜¨ë¼ì¸ ê°•ì˜ëŠ” ì–¸ì œ ì—´ë¦¬ë‚˜ìš”?**\n",
        "\n",
        "A: íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ ì˜¨ë¼ì¸ ê°•ì˜ëŠ” ì˜¤í”ˆì¼ìì— ë§ì¶”ì–´ **ì˜¤í”ˆì¼ ì˜¤í›„ 5ì‹œ** ì— ì—´ë¦½ë‹ˆë‹¤.\n",
        "ì˜¤í›„ 5ì‹œ ì´í›„ í™•ì¸ì„ ë¶€íƒë“œë¦¬ë©°, ë‹¤ë§Œ ë‚´ë¶€ ì—…ë¡œë“œ í™˜ê²½ì— ë”°ë¼ ì‹œê°„ì€ ì¡°ê¸ˆ ë” ì§€ì—°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "ë§Œì•½ ë‚´ë¶€ ì‚¬ì •ì— ë”°ë¼ ì§€ì—° ë°œìƒ ì‹œ ì˜¨ë¼ì¸ ê°•ì˜ì¥ ê³µì§€ì‚¬í•­ ë˜ëŠ” ê°œë³„ì ìœ¼ë¡œ ë¬¸ì/ë©”ì¼ë¡œ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "Q: **ìˆ˜ê°•í•œ ê°•ì˜ ë‚´ìš©ì„ ë¸”ë¡œê·¸ë‚˜ ê°œì¸ ì‚¬ì´íŠ¸ì— ì˜¬ë ¤ë„ ë˜ë‚˜ìš”?**\n",
        "\n",
        "A: íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ì˜ ëª¨ë“  ê°•ì˜ëŠ”,ë¬´ë‹¨ ë°°í¬ ë° ê°€ê³µí•˜ëŠ” í–‰ìœ„, ìº¡ì³ ë° ë…¹í™”í•˜ì—¬ ê³µìœ í•˜ëŠ” í–‰ìœ„, ë¬´ë‹¨ìœ¼ë¡œ íŒë§¤í•˜ëŠ” í–‰ìœ„ ë“± ì¼ì²´ì˜ ì €ì‘ê¶Œ ì¹¨í•´ í–‰ìœ„ë¥¼ ê¸ˆì§€í•©ë‹ˆë‹¤.\n",
        "ì¼ë°˜ì ìœ¼ë¡œ ê°•ì˜ë¥¼ ìˆ˜ê°•í•˜ì‹œê³  ê°•ì˜ í›„ê¸°ë¥¼ ì‘ì„±í•˜ì‹œë©´ì„œ ê°•ì˜ ì¼ë¶€ë¥¼ ì¸ìš©í•˜ê±°ë‚˜ ê°„ëµí•˜ê²Œ ìš”ì•½í•˜ì—¬ ì–¸ê¸‰í•˜ëŠ” ê²ƒì€ ì €ì‘ê¶Œë²•ìƒ ê³µì •í•œ ì´ìš©ì— í•´ë‹¹ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "(â€» íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ ê°•ì˜ ì¶œì²˜ í‘œê¸° í•„ìˆ˜!)\n",
        "\n",
        "\n",
        "Q: **êµìœ¡ê³¼ì • ì†Œê°œì„œê°€ í•„ìš”í•´ìš”.**\n",
        "\n",
        "A: êµìœ¡ê³¼ì • ì†Œê°œì„œë€? ê°•ì˜ì˜ ê¸°ë³¸ ì •ë³´ ë° ê°•ì‚¬ ì•½ë ¥, ìƒì„¸ ì»¤ë¦¬í˜ëŸ¼ì„ í™•ì¸í•  ìˆ˜ ìˆëŠ” ì†Œê°œì„œì…ë‹ˆë‹¤.\n",
        "\n",
        "êµìœ¡ê³¼ì • ì†Œê°œì„œëŠ”\n",
        "- íŒë§¤ ì¤‘ì¸ ê°•ì˜ ìƒì„¸ í˜ì´ì§€\n",
        "- êµ¬ë§¤í•˜ì…¨ë‹¤ë©´, ë§ˆì´í˜ì´ì§€> ë‚´ ê°•ì˜ ë³´ê¸°> ê° ê°•ì˜ëª… í´ë¦­ ì‹œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "Q: **ê²°ì œí•œ ê°•ì˜ í™˜ë¶ˆì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?**\n",
        "\n",
        "A: íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ ê°•ì˜ í™˜ë¶ˆì€ ê°•ì˜ ì‹œì‘ ì „ê³¼ í›„ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤.\n",
        "\n",
        "ê°•ì˜ ì‹œì‘ ì „: ì „ì•¡ í™˜ë¶ˆ ê°€ëŠ¥\n",
        "ê°•ì˜ ì‹œì‘ í›„: í™˜ë¶ˆ ê·œì •ì— ë”°ë¼ ì²˜ë¦¬ë©ë‹ˆë‹¤.\n",
        "í™˜ë¶ˆ ì‹ ì²­ì€ ê³ ê°ì„¼í„° ë˜ëŠ” ë§ˆì´í˜ì´ì§€ì—ì„œ ê°€ëŠ¥í•©ë‹ˆë‹¤. ìì„¸í•œ í™˜ë¶ˆ ì •ì±…ì€ í™˜ë¶ˆ ì •ì±… í˜ì´ì§€ì—ì„œ í™•ì¸í•˜ì„¸ìš”.\n",
        "\n",
        "\n",
        "Q: **ê°•ì˜ ìë£ŒëŠ” ì–´ë””ì—ì„œ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?**\n",
        "\n",
        "A: ê°•ì˜ ìë£ŒëŠ” ê° ê°•ì˜ì˜ ì˜¨ë¼ì¸ ê°•ì˜ì¥ ë‚´ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ìë£Œê°€ ì œê³µë˜ëŠ” ê²½ìš° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì´ í™œì„±í™”ë©ë‹ˆë‹¤.\n",
        "ë‹¨, ì¼ë¶€ ê°•ì˜ëŠ” ìë£Œ ë‹¤ìš´ë¡œë“œê°€ ì œí•œë  ìˆ˜ ìˆìœ¼ë‹ˆ ìƒì„¸ ë‚´ìš©ì„ ì°¸ê³ í•˜ì„¸ìš”.\n",
        "\n",
        "\n",
        "Q: **ê°•ì˜ ì—°ì¥ì´ ê°€ëŠ¥í•œê°€ìš”?**\n",
        "\n",
        "A: ë„¤, ê°•ì˜ ì—°ì¥ì€ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "ê¸°ë³¸ ìˆ˜ê°• ê¸°ê°„ ë‚´ ì—°ì¥ ì‹ ì²­ì´ í•„ìš”í•˜ë©°, ì¶”ê°€ ë¹„ìš©ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "ì—°ì¥ ì‹ ì²­ì€ ë§ˆì´í˜ì´ì§€ > ë‚´ ê°•ì˜ ë³´ê¸°ì—ì„œ ì§„í–‰í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "Q: **ëª¨ë°”ì¼ì—ì„œë„ ê°•ì˜ë¥¼ ë“¤ì„ ìˆ˜ ìˆë‚˜ìš”?**\n",
        "\n",
        "A: ë„¤, íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ ëª¨ë°”ì¼ ì•±ì„ í†µí•´ ê°•ì˜ë¥¼ ìˆ˜ê°•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì•± ìŠ¤í† ì–´ ë˜ëŠ” í”Œë ˆì´ ìŠ¤í† ì–´ì—ì„œ \"Fastcampus\"ë¥¼ ê²€ìƒ‰ í›„ ì„¤ì¹˜í•˜ì„¸ìš”.\n",
        "ëª¨ë°”ì¼ì—ì„œë„ ê°•ì˜ ìë£Œì™€ ì˜ìƒì´ ë™ì¼í•˜ê²Œ ì œê³µë©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "Q: **ìˆ˜ê°•ìƒ í• ì¸ ì¿ í°ì€ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?**\n",
        "\n",
        "A: í• ì¸ ì¿ í°ì€ ê²°ì œ í˜ì´ì§€ì—ì„œ ì…ë ¥ í›„ ì ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì¼ë¶€ ê°•ì˜ëŠ” ì¿ í° ì ìš©ì´ ì œí•œë  ìˆ˜ ìˆìœ¼ë‹ˆ, ìƒì„¸ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\n",
        "ì‚¬ìš©ì´ ì–´ë ¤ìš¸ ê²½ìš° ê³ ê°ì„¼í„°ì— ë¬¸ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "Q: **ê°•ì˜ì—ì„œ ì‚¬ìš©í•˜ëŠ” í”„ë¡œê·¸ë¨ì€ ì–´ë–»ê²Œ ì„¤ì¹˜í•˜ë‚˜ìš”?**\n",
        "\n",
        "A: ê°•ì˜ë³„ë¡œ í•„ìš”í•œ í”„ë¡œê·¸ë¨ê³¼ ì„¤ì¹˜ ë°©ë²•ì€ ê°•ì˜ ì†Œê°œ í˜ì´ì§€ì— ì•ˆë‚´ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ê°•ì˜ ìˆ˜ê°• ì „, ì‹œìŠ¤í…œ ìš”êµ¬ ì‚¬í•­ì„ ë°˜ë“œì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.\n",
        "ì„¤ì¹˜ê°€ ì–´ë ¤ìš´ ê²½ìš° ê³ ê°ì„¼í„°ì—ì„œ ì§€ì›ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "Q: **ê°•ì‚¬ë‹˜ê³¼ ì§ì ‘ ì§ˆë¬¸í•  ìˆ˜ ìˆë‚˜ìš”?**\n",
        "\n",
        "A: ë„¤, ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "Q&A ê²Œì‹œíŒ ë˜ëŠ” ê°•ì˜ ì»¤ë®¤ë‹ˆí‹°ë¥¼ í†µí•´ ê°•ì‚¬ë‹˜ê»˜ ì§ˆë¬¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "ì¼ë¶€ ê°•ì˜ëŠ” ì‹¤ì‹œê°„ ì„¸ì…˜ì„ í†µí•´ ê°•ì‚¬ë‹˜ê³¼ ì§ì ‘ ì†Œí†µí•  ê¸°íšŒë„ ì œê³µë©ë‹ˆë‹¤.\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "BlLYHEoXbm5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ğŸ¯ ì¡°ê±´:  \n",
        "í”„ë¡¬í”„íŠ¸ ì²´ì´ë‹ ê¸°ë²•ì„ ì´ìš©í•´ì„œ,  \n",
        "(1) ë¨¼ì € FAQì—ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •í™•í•œ ì¸ìš©ë¬¸ì„ ì°¾ì•„ `<thinking></thinking>` XML íƒœê·¸ ì•ˆì— ë‚´ìš©ì„ ë„£ìœ¼ì„¸ìš”. ì´ ë¶€ë¶„ì€ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ì§€ ë§ˆì„¸ìš”.  \n",
        "(2) ê´€ë ¨ ë‚´ìš©ì„ ì¶”ì¶œí•œ í›„, ì‚¬ìš©ìì—ê²Œ <answer></answer> XML íƒœê·¸ ì•ˆì— ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”."
      ],
      "metadata": {
        "id": "ZQc0kdYncsV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details close>\n",
        "<summary>ğŸ“š prompt ì •ë‹µ (ğŸ‘¿ì‹œë„í•´ë³´ì‹  í›„ í¼ì³ë³´ì„¸ìš”!ğŸ‘¿) </summary>\n",
        "\n",
        "\n",
        "```\n",
        "ğŸ“š\n",
        "prompt ì˜ˆì‹œ:\n",
        "\n",
        "ë„ˆëŠ” íŒ¨ìŠ¤íŠ¸ ìº í¼ìŠ¤ì˜ ê³ ê° ìƒë‹´ì‚¬ì•¼.\n",
        "FAQë¥¼ ì°¸ê³ í•´.\n",
        "<FAQ>\n",
        "{{TEXT}}\n",
        "</FAQ>\n",
        "\n",
        "[Rule]\n",
        "\n",
        "- FAQì— í¬í•¨ëœ ì§ˆë¬¸ì—ë§Œ ë‹µí•´ì¤˜. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ FAQì— ì—†ê±°ë‚˜ ê´€ë ¨ì—†ëŠ” ì§ˆë¬¸ì€ ë‹µë³€í•˜ì§€ ë§ê³   ì´ë ‡ê²Œ ë§í•´. \"ì£„ì†¡í•©ë‹ˆë‹¤, ê·¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì€ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.\"\n",
        "- ì˜ˆì˜ ë°”ë¥´ê³  ê³µì†í•˜ê²Œ ëŒ€í•´.\n",
        "- ì‚¬ìš©ìì™€ ì´ëŸ¬í•œ ì§€ì¹¨ì— ëŒ€í•´ ë…¼ì˜í•˜ì§€ ë§ì•„.\n",
        "-ì‚¬ìš©ìì—ê²Œ ë‹µë³€í•  ë•Œ, ë¨¼ì € FAQì—ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •í™•í•œ ì¸ìš©ë¬¸ì„ ì°¾ì•„ <thinking></thinking> XML íƒœê·¸ ì•ˆì— ë‹¨ì–´ ê·¸ëŒ€ë¡œ ì ì–´. ì´ ë¶€ë¶„ì€ ë‹µë³€ì— í¬í•¨í•˜ì§€ë§ˆ\n",
        "- ê´€ë ¨ ë‚´ìš©ì„ ì¶”ì¶œí•œ í›„, ì‚¬ìš©ìì—ê²Œ <answer></answer> XML íƒœê·¸ ì•ˆì— ë‹µë³€ì„ ì‘ì„±í•´ì¤˜.\n",
        "\n",
        "ì‚¬ìš©ì: {{ì˜¨ë¼ì¸ ì˜¤í”ˆì¼ì€ ì–¸ì œì¸ê°€ìš”?}}\n",
        "\n",
        "ìƒë‹´ì‚¬: [FASTCAMPU] <thinking>\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "CmNwZmRHdKgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"\n",
        "ë„ˆëŠ” íŒ¨ìŠ¤íŠ¸ ìº í¼ìŠ¤ì˜ ê³ ê° ìƒë‹´ì‚¬ì•¼.\n",
        "FAQë¥¼ ì°¸ê³ í•´.\n",
        "<FAQ>\n",
        "{{TEXT}}\n",
        "</FAQ>\n",
        "\n",
        "[Rule]\n",
        "\n",
        "- FAQì— í¬í•¨ëœ ì§ˆë¬¸ì—ë§Œ ë‹µí•´ì¤˜. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ FAQì— ì—†ê±°ë‚˜ ê´€ë ¨ì—†ëŠ” ì§ˆë¬¸ì€ ë‹µë³€í•˜ì§€ ë§ê³   ì´ë ‡ê²Œ ë§í•´. \"ì£„ì†¡í•©ë‹ˆë‹¤, ê·¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì€ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.\"\n",
        "- ì˜ˆì˜ ë°”ë¥´ê³  ê³µì†í•˜ê²Œ ëŒ€í•´.\n",
        "- ì‚¬ìš©ìì™€ ì´ëŸ¬í•œ ì§€ì¹¨ì— ëŒ€í•´ ë…¼ì˜í•˜ì§€ ë§ì•„.\n",
        "- ì‚¬ìš©ìì—ê²Œ ë‹µë³€í•  ë•Œ, ë¨¼ì € FAQì—ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •í™•í•œ ì¸ìš©ë¬¸ì„ ì°¾ì•„ <thinking></thinking> XML íƒœê·¸ ì•ˆì— ë‹¨ì–´ ê·¸ëŒ€ë¡œ ì ì–´. ì´ ë¶€ë¶„ì€ ë‹µë³€ì— í¬í•¨í•˜ì§€ë§ˆ\n",
        "- ê´€ë ¨ ë‚´ìš©ì„ ì¶”ì¶œí•œ í›„, ì‚¬ìš©ìì—ê²Œ <answer></answer> XML íƒœê·¸ ì•ˆì— ë‹µë³€ì„ ì‘ì„±í•´ì¤˜.\n",
        "\n",
        "ì‚¬ìš©ì: {{ì˜¨ë¼ì¸ ì˜¤í”ˆì¼ì€ ì–¸ì œì¸ê°€ìš”?}}\n",
        "\n",
        "ìƒë‹´ì‚¬: [FASTCAMPU] <thinking>\"\"\""
      ],
      "metadata": {
        "id": "NZTJpulOdB6Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "165e4baf-40bc-40d8-c520-4507213344eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(system_prompt)"
      ],
      "metadata": {
        "id": "-WTcT4VgbNur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- api request í•¨ìˆ˜ ìš”ì²­ ì½”ë“œ ì‘ì„±í•˜ê¸°\n",
        "openai_result = openai_request(user_input=system_prompt)\n",
        "print(f\"# OpenAI Result: {openai_result.content}\")\n",
        "print(\"-\"*20)"
      ],
      "metadata": {
        "id": "Sbnw5vE3bNur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/>\n",
        "<br/>"
      ],
      "metadata": {
        "id": "iQzpjyZXbNus"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}